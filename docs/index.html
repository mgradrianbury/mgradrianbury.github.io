<html lang="pl">
<head><title></title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-2">
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)">
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)">
<!-- html -->
<meta name="src" content="praca_magisterska.tex">
<link rel="stylesheet" type="text/css" href="praca_magisterska.css">
</head><body
>




<!--l. 1--><p class="indent" >


<div class="center"
>
<!--l. 2--><p class="noindent" >
<!--l. 4--><p class="noindent" ><span
class="qx-lmbx-12x-x-144">UNIWERSYTET PEDAGOGICZNY</span><br />
<span
class="qx-lmr-17">im. Komisji Edukacji Narodowej w Krakowie</span><br /><br />
 <img
         src="../images/logoUP_pl-.png" alt="PIC"
         width="18" height="18" ><br /><br />
<span
class="qx-lmbx-12x-x-120">INSTYTUT INFORMATYKI</span>
Kierunek: INFORMATYKA<br />
specjalno&#347;&#263;: -
<!--l. 18--><p class="noindent" ><span
class="qx-lmbx-12x-x-144">Adrian Bury</span><br />
<!--l. 19--><p class="noindent" ><span
class="qx-lmr-12x-x-120">Nr albumu: 149618</span><br />
<!--l. 24--><p class="noindent" > <span
class="qx-lmbx-12x-x-144">Zastosowanie g&#322;&#281;bokiej sieci neuronowej</span>
<span
class="qx-lmbx-12x-x-144">o architekturze FaceNet do rozpoznawania twarzy</span>
<br /><br />
                                                                                 <div class="flushright"
>
<!--l. 27--><p class="noindent" >
 <!--tex4ht:inline--><div class="tabular"> <table id="TBL-1" class="tabular"
cellspacing="0" cellpadding="0"
><colgroup id="TBL-1-1g"><col
id="TBL-1-1"><col
id="TBL-1-2"></colgroup><tr
 id="TBL-1-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-1-1"
class="td11"> <span
class="qx-lmr-12x-x-120">Praca magisterska                </span></td>
</tr><tr
 id="TBL-1-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-2-1"
class="td11"> <span
class="qx-lmr-12x-x-120">napisana pod kierunkiem        </span></td>
</tr><tr
 id="TBL-1-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-3-1"
class="td11"> <span
class="qx-lmr-12x-x-120">dr hab. in</span><span
class="qx-lmr-12x-x-120">&#380;. Tomasza Hachaja </span></td></tr></table>
</div></div>
<!--l. 39--><p class="noindent" ><span
class="qx-lmr-12x-x-120">Kraków 2021</span>
</div>




<!--l. 31--><p class="indent" >




   <h2 class="likechapterHead"><a
 id="x1-1000"></a>Spis tre&#347;ci</h2>
   <div class="tableofcontents">
   <span class="chapterToc" >1 <a
href="#x1-40001" id="QQ2-1-4">Cel i zakres pracy</a></span>
<br />   <span class="chapterToc" >2 <a
href="#x1-50002" id="QQ2-1-5">Koncepcja dzia&#322;ania systemu</a></span>
<br />   <span class="chapterToc" >3 <a
href="#x1-60003" id="QQ2-1-6">Wybór technologii oraz narz&#281;dzi</a></span>
<br />   &#x00A0;<span class="sectionToc" >3.1 <a
href="#x1-70003.1" id="QQ2-1-7">Wykrywanie twarzy na zdj&#281;ciu</a></span>
<br />   &#x00A0;<span class="sectionToc" >3.2 <a
href="#x1-80003.2" id="QQ2-1-8">FaceNet</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >3.2.1 <a
href="#x1-90003.2.1" id="QQ2-1-9">Zasada dzia&#322;ania</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >3.2.2 <a
href="#x1-100003.2.2" id="QQ2-1-10">Trenowanie sieci</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >3.2.3 <a
href="#x1-110003.2.3" id="QQ2-1-11">Wp&#322;yw wielko&#347;ci zdj&#281;cia na dzia&#322;anie sieci</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >3.2.4 <a
href="#x1-120003.2.4" id="QQ2-1-12">U&#380;ycie wytrenowanej sieci</a></span>
<br />   &#x00A0;<span class="sectionToc" >3.3 <a
href="#x1-130003.3" id="QQ2-1-13">Kadrowanie i standaryzacja</a></span>
<br />   &#x00A0;<span class="sectionToc" >3.4 <a
href="#x1-140003.4" id="QQ2-1-14">Klasyfikator SVM</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >3.4.1 <a
href="#x1-150003.4.1" id="QQ2-1-15">Margines twardy</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >3.4.2 <a
href="#x1-160003.4.2" id="QQ2-1-16">Margines mi&#281;kki</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >3.4.3 <a
href="#x1-170003.4.3" id="QQ2-1-17">Klasyfikacja nieliniowa</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >3.4.4 <a
href="#x1-180003.4.4" id="QQ2-1-18">Klasyfikacja wieloklasowa</a></span>
<br />   &#x00A0;<span class="sectionToc" >3.5 <a
href="#x1-190003.5" id="QQ2-1-19">Obs&#322;uga systemu</a></span>
<br />   <span class="chapterToc" >4 <a
href="#x1-200004" id="QQ2-1-20">Implementacja systemu</a></span>
<br />   &#x00A0;<span class="sectionToc" >4.1 <a
href="#x1-210004.1" id="QQ2-1-21">Kadrowanie twarzy</a></span>
<br />   &#x00A0;<span class="sectionToc" >4.2 <a
href="#x1-220004.2" id="QQ2-1-22">Generowanie wektora cech</a></span>
<br />   &#x00A0;<span class="sectionToc" >4.3 <a
href="#x1-230004.3" id="QQ2-1-23">Ocena podobie&#324;stwa twarzy</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >4.3.1 <a
href="#x1-240004.3.1" id="QQ2-1-24">Poszukiwanie odleg&#322;o&#347;ci</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >4.3.2 <a
href="#x1-250004.3.2" id="QQ2-1-25">Odleg&#322;o&#347;&#263; o najwi&#281;kszej skuteczno&#347;ci</a></span>
<br />   &#x00A0;<span class="sectionToc" >4.4 <a
href="#x1-260004.4" id="QQ2-1-26">Klasyfikator</a></span>
<br />   &#x00A0;<span class="sectionToc" >4.5 <a
href="#x1-270004.5" id="QQ2-1-27">Strona internetowa</a></span>
<br />   <span class="chapterToc" >5 <a
href="#x1-280005" id="QQ2-1-28">Testowanie systemu</a></span>
<br />   &#x00A0;<span class="sectionToc" >5.1 <a
href="#x1-290005.1" id="QQ2-1-29">Wgranie zdj&#281;&#263; do systemu</a></span>
<br />   &#x00A0;<span class="sectionToc" >5.2 <a
href="#x1-300005.2" id="QQ2-1-30">Zdj&#281;cie niezawieraj&#261;ce twarzy</a></span>
<br />   &#x00A0;<span class="sectionToc" >5.3 <a
href="#x1-310005.3" id="QQ2-1-31">Zdj&#281;cie osoby nieznanej systemowi</a></span>


<br />   &#x00A0;<span class="sectionToc" >5.4 <a
href="#x1-320005.4" id="QQ2-1-32">Zdj&#281;cie osoby znanej systemowi</a></span>
<br />   &#x00A0;<span class="sectionToc" >5.5 <a
href="#x1-330005.5" id="QQ2-1-33"><span
class="qx-lmr-17x-x-98">Skuteczno&#347;&#263; algorytmu rozpoznawania twarzy</span></a></span>
<br />   <span class="chapterToc" > <a
href="#Q1-1-35">Podsumowanie</a></span>
<br />   <span class="chapterToc" > <a
href="#Q1-1-37">Spis rysunków</a></span>
   </div>


   <h3 class="likesectionHead"><a
 id="x1-2000"></a>Streszczenie</h3>
<!--l. 3--><p class="noindent" >W rozdziale pierwszym zosta&#322;y poruszone zagadnienia zwi&#261;zane z rozpoznawaniem twarzy
oraz zosta&#322; postawiony cel napisania aplikacji, za pomoc&#261; której u&#380;ytkownik b&#281;dzie móg&#322;
uzyska&#263; informacj&#281; na temat osoby przedstawionej na wys&#322;anym zdj&#281;ciu pod
warunkiem, &#380;e do aplikacji zosta&#322;y wcze&#347;niej dostarczone zdj&#281;cia reprezentuj&#261;ce dan&#261;
osob&#281;. W rozdziale drugim zosta&#322;a omówiona koncepcja dzia&#322;ania aplikacji, a w
rozdziale trzecim zosta&#322;y wybrane i opisane technologie, które zostan&#261; u&#380;yte
do jej napisania. Rozdzia&#322; czwarty szczegó&#322;owo opisuje proces implementacji
poszczególnych elementów aplikacji oraz omawia sposób znalezienia progu, za
pomoc&#261; której zostanie uznane, &#380;e dana osoba jest znana/nieznana aplikacji.
Ostatni rozdzia&#322; przedstawia sposób testowania oraz zawiera analiz&#281; otrzymanych
wyników.
<!--l. 18--><p class="noindent" >
   <h3 class="likesectionHead"><a
 id="x1-3000"></a>Abstract</h3>
<!--l. 20--><p class="noindent" >In chapter one is discussed issues related to face recognition and is set the goal of writing
an application to help find information who is pictured on the sent photo if the person has
been previously uploaded to the serwer. The second chapter discusses the concept of the
system operation and in the third chapter is chosen and described technologies that will
be used to meet the expectations. The fourth chapter describes in detail the process of
implementing individual system components and discusses the methodology of finding
the threshold, by means of which the system recognizes that a given person is
known. The last chapter shows tests of implemented system and analysis the
results.






   <h2 class="chapterHead"><span class="titlemark">Rozdzia&#322;&#x00A0;1</span><br /><a
 id="x1-40001"></a>Cel i zakres pracy</h2>
<!--l. 3--><p class="noindent" >Rozpoznawanie twarzy to zagadnienie z dziedziny klasyfikacji, które polega na rozpoznawaniu
i identyfikacji to&#380;samo&#347;ci osoby na podstawie okre&#347;lonych wzorców&#x00A0;[<span
class="qx-lmbx-12">william2019face</span>].
Innymi s&#322;owy, rozpoznawanie twarzy to wykrycie obszaru na fotografii, w którym znajduje
si&#281; twarz oraz weryfikacja to&#380;samo&#347;ci.
<!--l. 9--><p class="indent" >   Problem identyfikacji to&#380;samo&#347;ci jest ogólnie znany jako problem klasyfikacji,
czyli okre&#347;lenie etykiety dostarczonego zdj&#281;cia twarzy na podstawie aktualnego
zbioru zdj&#281;&#263;. Problem mo&#380;e by&#263; postrzegany jako zapytanie systemu &#8220;kim jest osoba
przedstawiona na zdj&#281;ciu?&#8221;. Przyk&#322;adem procesu, gdzie jest stosowana identyfikacja, to
proces wyszukiwana to&#380;samo&#347;ci. Po dostarczeniu pliku system przeszukuje baz&#281;
dost&#281;pnych zdj&#281;&#263; w celu znalezienia pasuj&#261;cego zdj&#281;cia i je&#380;eli zdj&#281;cie zostanie
dopasowane, to system zwróci informacj&#281; o to&#380;samo&#347;ci.
<!--l. 16--><p class="indent" >   Weryfikacja to proces sprawdzaj&#261;cy prawdziwo&#347;&#263;, przydatno&#347;&#263; lub prawid&#322;owo&#347;&#263;
czego&#347;&#x00A0;[<span
class="qx-lmbx-12">sjp&#x02D9;pwn&#x02D9;1996</span>]. Oznacza to, &#380;e weryfikacja na podstawie zdj&#281;cia twarzy b&#281;dzie
oznacza&#263; proces polegaj&#261;cy na sprawdzeniu, czy deklarowana to&#380;samo&#347;&#263; zgadza si&#281; z
przypisanym do deklaracji zdj&#281;ciem twarzy i je&#380;eli tak, to akceptowanie, je&#380;eli nie to
odrzucanie o&#347;wiadczenia. Zapytanie, jakie zadaje si&#281; wtedy systemowi to &#8220;czy podane
o&#347;wiadczenie zgadza si&#281; ze zdj&#281;ciem zapisanej w systemie osoby?&#8221;. Przyk&#322;adem
weryfikacji to&#380;samo&#347;ci za pomoc&#261; twarzy jest odblokowywanie smartfonów z
wykorzystaniem kamery. Aplikacja w smartfonie sprawdza wtedy, czy zdj&#281;cie
osoby z kamery zgadza si&#281; ze zdj&#281;ciem zapisanym w pami&#281;ci. Je&#380;eli zdj&#281;cia,
zapisane w pami&#281;ci oraz dostarczone z kamery, zgadzaj&#261; si&#281;, to telefon zostanie
odblokowany.


<!--l. 28--><p class="indent" >   System, który implementuje weryfikacj&#281; lub identyfikacj&#281; na podstawie twarzy,
mo&#380;e znale&#378;&#263; zastosowanie do wykonywania automatycznego oznaczania osób na
zdj&#281;ciach&#x00A0;[<span
class="qx-lmbx-12">facebook-aut-tag</span>], przeszukiwania stron internetowych w celu znalezienie
zdj&#281;cia przedstawiaj&#261;cego dan&#261; osob&#281;&#x00A0;[<span
class="qx-lmbx-12">pimeyes</span>] czy zautomatyzowanego grupowania
zdj&#281;&#263; na podstawie twarzy na nich si&#281; znajduj&#261;cych&#x00A0;[<span
class="qx-lmbx-12">google-photos&#x02D9;groupby</span>].
<!--l. 33--><p class="indent" >   Celem pracy dyplomowej jest utworzenie systemu, którego zadaniem b&#281;dzie
rozpoznanie osoby przedstawionej na zdj&#281;ciu. Zakres prac obejmuje implementacj&#281; strony
internetowej, za pomoc&#261; której u&#380;ytkownik b&#281;dzie mia&#322; mo&#380;liwo&#347;&#263; przes&#322;ania wybranego
przez siebie zdj&#281;cia, oraz systemu, który zwróci informacj&#281; na temat osoby widniej&#261;cej na
owym zdj&#281;ciu (przesy&#322;anym za pomoc&#261; strony internetowej), pod warunkiem, &#380;e ta osoba
zostanie znaleziona w bazie zdj&#281;&#263;. W systemie zostanie u&#380;yta g&#322;&#281;boka sie&#263; neuronowa o
architekturze FaceNet do badania podobie&#324;stwa pomi&#281;dzy poszczególnymi twarzami. Aby
spe&#322;ni&#263; wszystkie oczekiwania, które zosta&#322;y postawione systemowi, nale&#380;y wykona&#263;
nast&#281;puj&#261;ce kroki:
      <ol  class="enumerate1" >
      <li
  class="enumerate" id="x1-4002x1">sformu&#322;owa&#263; koncepcj&#281; dzia&#322;ania systemu,
      </li>
      <li
  class="enumerate" id="x1-4004x2">wybra&#263; odpowiednie technologie oraz narz&#281;dzia,
      </li>
      <li
  class="enumerate" id="x1-4006x3">zaimplementowa&#263; poszczególne elementy systemu,
      </li>
      <li
  class="enumerate" id="x1-4008x4">przetestowa&#263; system.</li></ol>


   <h2 class="chapterHead"><span class="titlemark">Rozdzia&#322;&#x00A0;2</span><br /><a
 id="x1-50002"></a>Koncepcja dzia&#322;ania systemu</h2>
<!--l. 3--><p class="noindent" >System ma udost&#281;pnia&#263; u&#380;ytkownikowi interfejs graficzny, za pomoc&#261; którego b&#281;dzie mia&#322;
mo&#380;liwo&#347;&#263; wys&#322;ania dowolnego zdj&#281;cia. W tym celu zostanie przygotowana strona
internetowa, która udost&#281;pni formularz z mo&#380;liwo&#347;ci&#261; wyboru pliku graficznego. Po
wybraniu zdj&#281;cia z dysku u&#380;ytkownika plik ten zostanie wys&#322;any do systemu.
System b&#281;dzie mia&#322; za zadanie wykry&#263; twarz znajduj&#261;c&#261; si&#281; na zdj&#281;ciu i tak
wykadrowa&#263;, aby znajdowa&#322;a si&#281; na nim tylko twarz. Je&#380;eli na zdj&#281;ciu nie zostanie
znaleziona twarz, system zwróci odpowiedni komunikat o b&#322;&#281;dzie. Kolejnym krokiem
b&#281;dzie sprawdzenie, czy osoba przes&#322;ana na zdj&#281;ciu znajduje si&#281; w bazie. Po
uzyskaniu pozytywnego wyniku nast&#261;pi klasyfikacja zdj&#281;cia za pomoc&#261; klasyfikatora i
zwrócenie odpowiedniej informacji u&#380;ytkownikowi korzystaj&#261;cego z systemu. W
przeciwnym wypadku zostanie zwrócony komunikat, &#380;e dana osoba nie istnieje
w bazie zdj&#281;&#263;. Schemat blokowy opisanych procesów zosta&#322; przedstawiony na
rysunku&#x00A0;<a
href="#x1-5001r1">2.1<!--tex4ht:ref: fig:schemat_blokowy_systemu --></a>.
<!--l. 18--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-5001r1"></a>


<!--l. 20--><p class="noindent" > <img
        src="../images/schemat_blokowy_systemu-.png" alt="PIC"
        width="426" height="426" >
<a
 id="x1-5002"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;2.1: </span><span
class="content">Schemat blokowy zaprojektowanego systemu</span></div><!--tex4ht:label?: x1-5001r2 -->
<!--l. 23--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 24--><p class="indent" >   </div><hr class="endfigure">






   <h2 class="chapterHead"><span class="titlemark">Rozdzia&#322;&#x00A0;3</span><br /><a
 id="x1-60003"></a>Wybór technologii oraz narz&#281;dzi</h2>
   <h3 class="sectionHead"><span class="titlemark">3.1   </span> <a
 id="x1-70003.1"></a>Wykrywanie twarzy na zdj&#281;ciu</h3>
<!--l. 6--><p class="noindent" >Wykrywanie twarzy to pierwszy krok w zaprojektowanym systemie. Z powodu tego, &#380;e
jest on umieszczony na samym pocz&#261;tku, proces ten musi by&#263; maksymalnie skuteczny.
Je&#380;eli na zdj&#281;ciu nie zostanie wykryta twarz, to ca&#322;y proces zako&#324;czy si&#281; z negatywnym
rezultatem. <span
class="qx-lmbx-12">Twarzy nie b&#281;dzie mo</span><span
class="qx-lmbx-12">&#380;na zidentyfikowa&#263;, je</span><span
class="qx-lmbx-12">&#380;eli nie zostanie ona</span>
<span
class="qx-lmbx-12">znaleziona. </span>Niestety twarz ludzka jest obiektem dynamicznym i ma du&#380;y stopie&#324;
zmienno&#347;ci w wygl&#261;dzie, co sprawia, &#380;e wykrywanie twarzy jest trudnym problemem w
widzeniu komputerowym&#x00A0;[<span
class="qx-lmbx-12">HJELMAS2001236</span>].
<!--l. 13--><p class="indent" >   W artykule z 2016 roku zatytu&#322;owanym &#8220;Joint Face Detection and Alignment Using
Multitask Cascaded Convolutional Networks&#8221;&#x00A0;[<span
class="qx-lmbx-12">zhang2016joint</span>] zosta&#322;a zaproponowana
wielozadaniowa kaskadowa konwolucyjna sie&#263; neuronowa (ang. Multi-Task Cascaded
Convolutional Neural Networks - MTCNN) do wykrywania twarzy. Sie&#263; ta zyska&#322;a du&#380;a
popularno&#347;&#263;, poniewa&#380; osi&#261;gn&#281;&#322;a wówczas najlepszy wyniki w wykrywaniu twarzy na
zdj&#281;ciach dla wybranych zbiorów danych. Kolejn&#261; zalet&#261; zaproponowanej sieci neuronowej
jest to, &#380;e jest w stanie rozpozna&#263; punkty orientacyjne twarzy, takie jak oczy, usta i
nos.
<!--l. 22--><p class="indent" >   W internecie znajduje si&#281; spora liczba implementacji MTCNN&#x00A0;[<span
class="qx-lmbx-12">mtznn&#x02D9;all&#x02D9;impls</span>]. Spo&#347;ród
dost&#281;pnych zosta&#322;a wybrana sie&#263; napisana przez <span
class="qx-lmri-12">Iván de Paz Centeno </span>i udost&#281;pniona na portalu
GitHub<span class="footnote-mark"><a
href="praca_magisterska2.html#fn1x3"><sup class="textsuperscript">1)</sup></a></span><a
 id="x1-7001f1"></a>
(<a
href="https://github.com/ipazc/mtcnn" class="url" ><span
class="qx-lmtt-12">https://github.com/ipazc/mtcnn</span></a>) na zasadach licencji
MIT<span class="footnote-mark"><a
href="praca_magisterska3.html#fn2x3"><sup class="textsuperscript">2)</sup></a></span><a
 id="x1-7002f2"></a> &#x00A0;[<span
class="qx-lmbx-12">ipazc/mtcnn</span>].
G&#322;ówn&#261; zalet&#261; wybranej implementacji jest &#322;atwo&#347;&#263; u&#380;ycia. Sie&#263; zosta&#322;a
napisana w j&#281;zyku programowania python w bibliotece TensorFlow
i ca&#322;o&#347;&#263; udost&#281;pniona jako pakiet z mo&#380;liwo&#347;ci&#261; instalacji przez


PIP<span class="footnote-mark"><a
href="praca_magisterska4.html#fn3x3"><sup class="textsuperscript">3)</sup></a></span><a
 id="x1-7003f3"></a> .
   <h3 class="sectionHead"><span class="titlemark">3.2   </span> <a
 id="x1-80003.2"></a>FaceNet</h3>
<!--l. 39--><p class="noindent" >FaceNet to architektura oparta na g&#322;&#281;bokiej sieci neuronowej, która bezpo&#347;rednio uczy si&#281;
mapowania z obrazów twarzy do n-wymiarowych wektorów, gdzie poszczególne warto&#347;ci
wektora charakteryzuj&#261; dan&#261; twarz. Wymiarowo&#347;&#263; wektora jest zale&#380;na od konkretnej
implementacji. W przestrzeni sk&#322;adaj&#261;cej si&#281; z wygenerowanych wektorów odleg&#322;o&#347;ci
pomi&#281;dzy wektorami, mierzone za pomoc&#261; metryki euklidesowej, bezpo&#347;rednio
odpowiadaj&#261; mierze podobie&#324;stwa twarzy. Oznacza to, &#380;e zadania polegaj&#261;ce na
identyfikacji, weryfikacji czy grupowaniu sprowadzaj&#261; si&#281; do pomiaru odleg&#322;o&#347;ci
pomi&#281;dzy poszczególnymi wektorami cech&#x00A0;[<span
class="qx-lmbx-12">schroff2015facenet</span>]. Wizualizacja
procesu mapowania zdj&#281;cia do przestrzeni euklidesowej zosta&#322;a przedstawiona na
rysunku&#x00A0;<a
href="#x1-8001r1">3.1<!--tex4ht:ref: fig:facenet_zastosowanie --></a>.
<!--l. 50--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-8001r1"></a>


<!--l. 52--><p class="noindent" > <img
        src="../images/facenet_euc-.png" alt="PIC"
        width="341" height="341" >
<a
 id="x1-8002"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;3.1: </span><span
class="content">Wizualizacja przestrzeni sk&#322;adaj&#261;cej si&#281; z wygenerowanych wektorów.
Odleg&#322;o&#347;ci mierzone metryk&#261; euklidesow&#261; pomi&#281;dzy wektorami reprezentuj&#261;cymi te
same osoby s&#261; mniejsze wzgl&#281;dem wektorów reprezentuj&#261;cych inne osoby. Liter&#261; &#8220;A&#8221;
zosta&#322;y oznaczone zdj&#281;cia przedstawiaj&#261;ce t&#281; sam&#261; osob&#281;. </span></div><!--tex4ht:label?: x1-8001r3.2 -->
<!--l. 60--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 61--><p class="indent" >   </div><hr class="endfigure">


   <h4 class="subsectionHead"><span class="titlemark">3.2.1   </span> <a
 id="x1-90003.2.1"></a>Zasada dzia&#322;ania</h4>
<!--l. 68--><p class="noindent" >Po dostarczeniu danego zdj&#281;cia do sieci nast&#281;puje wieloetapowa filtracja przy u&#380;yciu
filtrów splotowych, aby wydoby&#263; z obrazu na wej&#347;ciu wyró&#380;niaj&#261;ce si&#281; cechy (ang.
convolution layer) oraz wykorzystywane s&#261; operatory &#322;&#261;czenia w celu zredukowania
wymiaru danych (ang. pooling layer). Operacje te s&#261; pewnego rodzaju kompresj&#261;, której
zadaniem jest zmniejszenie ilo&#347;ci informacji na temat danej rzeczy (w tym wypadku
zdj&#281;cia twarzy) bez utraty kluczowych informacji. Jako wynik dzia&#322;ania sieci
otrzymywany jest wektor, który przechowuje skompresowane informacje na temat
dostarczonego zdj&#281;cia. Informacje jak&#261; s&#261; w nim przechowywane s&#261; trudne, o ile w ogóle
mo&#380;liwe do zinterpretowania.
<!--l. 77--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">3.2.2   </span> <a
 id="x1-100003.2.2"></a>Trenowanie sieci</h4>
<!--l. 79--><p class="noindent" >W celu wytrenowania sieci, aby generowany wektor dok&#322;adnie odwzorowywa&#322;
dostarczone zdj&#281;cie, wykorzystywana jest funkcja strat <span
class="qx-lmri-12">triplet loss</span>. Jej zadaniem jest
minimalizowanie odleg&#322;o&#347;ci pomi&#281;dzy prawdziwymi wyra&#380;eniami oraz maksymalizowanie
dla fa&#322;szywych&#x00A0;[<span
class="qx-lmbx-12">chechik2010large</span>]. Innymi s&#322;owy, celem jest, aby odleg&#322;o&#347;ci mi&#281;dzy
wektorami cech tych samych osób by&#322;y jak najmniejsze, a odleg&#322;o&#347;ci pomi&#281;dzy wektorami
ró&#380;nych osób &#8212; maksymalne. Wzór matematyczny opisuj&#261;cy funkcj&#281; <span
class="qx-lmri-12">triplet loss </span>zosta&#322;
przedstawiony równaniem&#x00A0;<a
href="#x1-10001r1">3.1<!--tex4ht:ref: eq:triplet_loss --></a>&#x00A0;[<span
class="qx-lmbx-12">schroff2015facenet</span>], natomiast zasada dzia&#322;ania w
sposób graficzny przedstawiona na rysunku&#x00A0;<a
href="#x1-10002r2">3.2<!--tex4ht:ref: fig:triplet_loss --></a>.
   <table
class="equation"><tr><td><a
 id="x1-10001r1"></a>
   <center class="math-display" >
<img
src="praca_magisterska0x.png" alt="         &#x2211;N
     L =    [&#x2225;f(xa) - f(xp)&#x2225;2 - &#x2225;f (xa) - f (xn)&#x2225;2+ &#x03B1;]+
           i     i        i 2        i       i  2

gdzie
    a
   xi -wektor zdj&#281;cia wzorcowego
   xp -wektor zdj&#281;cia &#8220;prawdziwego &#8221; wzgl &#281;dem wzorca
    i
   xn -wektor zdj&#281;cia &#8220;fa&#322;szywego &#8221; wzgl&#281;dem  wzorca
    i
   &#x03B1;  -margines  odleg&#322;o&#347;ci pomi &#281;dzy wektorami
" class="math-display" ></center></td><td class="equation-label">(3.1)</td></tr></table>
<!--l. 100--><p class="nopar" >
<!--l. 102--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-10002r2"></a>


<!--l. 104--><p class="noindent" > <img
        src="../images/triplet_loss-.png" alt="PIC"
        width="426" height="426" >
<a
 id="x1-10003"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;3.2: </span><span
class="content">Uproszczony schemat obrazuj&#261;cy zasad&#281; dzia&#322;ania funkcji strat <span
class="qx-lmri-12">triplet</span>
<span
class="qx-lmri-12">loss </span></span></div><!--tex4ht:label?: x1-10002r3.2 -->
<!--l. 107--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 108--><p class="indent" >   </div><hr class="endfigure">
<!--l. 110--><p class="indent" >   Poszczególne etapy trenowania sieci o architekturze FaceNet zosta&#322;y przedstawione na
rysunku&#x00A0;<a
href="#x1-10014r3">3.3<!--tex4ht:ref: fig:facenet_arch --></a>. Ca&#322;o&#347;&#263; procesu uczenia si&#281; sieci FaceNet, mo&#380;na w uproszczeniu
podsumowa&#263; w nast&#281;puj&#261;cych krokach:
      <ol  class="enumerate1" >
      <li
  class="enumerate" id="x1-10005x1">zdefiniowanie parametrów pocz&#261;tkowych sieci,
      </li>
      <li
  class="enumerate" id="x1-10007x2">wygenerowanie wektorów cech twarzy,
      </li>
      <li
  class="enumerate" id="x1-10009x3">u&#380;ycie funkcji strat <span
class="qx-lmri-12">triplet loss</span>,
      </li>
      <li
  class="enumerate" id="x1-10011x4">dostosowanie si&#281; parametrów sieci tak, aby przyk&#322;ad pozytywny by&#322; bli&#380;ej
      zdj&#281;cia wzorcowego, ni&#380; przyk&#322;ad negatywny,
      </li>
      <li
  class="enumerate" id="x1-10013x5">powrót do kroku drugiego tak d&#322;ugo, a&#380; zwracane wektory osi&#261;gn&#261; zadan&#261;
      dok&#322;adno&#347;&#263;.</li></ol>
<!--l. 124--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-10014r3"></a>


<!--l. 126--><p class="noindent" > <img
        src="../images/facenet_arch-.png" alt="PIC"
        width="426" height="426" >
<a
 id="x1-10015"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;3.3:  </span><span
class="content">Proces  uczenia  si&#281;  sieci  o  architekturze  FaceNet  z  podzia&#322;em  na
poszczególne etapy </span></div><!--tex4ht:label?: x1-10014r3.2 -->
<!--l. 129--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 130--><p class="indent" >   </div><hr class="endfigure">
   <h4 class="subsectionHead"><span class="titlemark">3.2.3   </span> <a
 id="x1-110003.2.3"></a>Wp&#322;yw wielko&#347;ci zdj&#281;cia na dzia&#322;anie sieci</h4>
<!--l. 134--><p class="noindent" >W pracy pod tytu&#322;em <span
class="qx-lmri-12">Facenet: A unified embedding for face recognition and</span>
<span
class="qx-lmri-12">clustering</span>&#x00A0;[<span
class="qx-lmbx-12">schroff2015facenet</span>] zosta&#322;a wytrenowana sie&#263; o architekturze FaceNet na
zdj&#281;ciach w formacie JPEG o rozmiarach 220 na 220 pikseli. Podczas testowania
wytrenowanej sieci, po dostarczeniu zdj&#281;&#263; o mniejszych rozmiarach (wzgl&#281;dem rozmiarów
zdj&#281;&#263;, na których sie&#263; by&#322;a trenowana) okaza&#322;o si&#281;, &#380;e sie&#263; ta jest równie&#380; bardzo
skuteczna. Sie&#263; mia&#322;a akceptowaln&#261; skuteczno&#347;&#263; nawet po dostarczeniu zdj&#281;&#263; o rozmiarach
80 na 80 pikseli. Trenowanie sieci na zdj&#281;ciach o mniejszej rozdzielczo&#347;ci mog&#322;oby jeszcze
poprawi&#263; ten wynik. Dok&#322;adne informacje na temat wp&#322;ywu liczby pikseli na skuteczno&#347;&#263;
sieci zosta&#322;y przedstawione w tabeli&#x00A0;<a
href="#x1-11001r1">3.1<!--tex4ht:ref: tab:quality_pixels_to_rate --></a>
   <div class="table">


<!--l. 143--><p class="indent" >   <a
 id="x1-11001r1"></a><hr class="float"><div class="float"
>


<a
 id="x1-11002"></a>
 <div class="caption"
><span class="id">Tablica&#x00A0;3.1: </span><span
class="content">Wp&#322;yw jako&#347;ci zdj&#281;cia oraz liczby pikseli na skuteczno&#347;&#263; sieci FaceNet.
&#377;ród&#322;o: [<span
class="qx-lmbx-12">schroff2015facenet</span>] </span></div><!--tex4ht:label?: x1-11001r3.2 -->
<div class="minipage"><div class="tabular"> <table id="TBL-2" class="tabular"
cellspacing="0" cellpadding="0"
><colgroup id="TBL-2-1g"><col
id="TBL-2-1"></colgroup><colgroup id="TBL-2-2g"><col
id="TBL-2-2"></colgroup><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-2-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-1-1"
class="td11"> Liczba pikseli         </td><td  style="white-space:nowrap; text-align:left;" id="TBL-2-1-2"
class="td11"> Skuteczno&#347;&#263;  </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-2-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-2-1"
class="td11"> 1 600 &#x00A0;     (40x40)   </td><td  style="white-space:nowrap; text-align:left;" id="TBL-2-2-2"
class="td11"> 37.8%         </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-2-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-3-1"
class="td11"> 6 400 &#x00A0;     (80x80)   </td><td  style="white-space:nowrap; text-align:left;" id="TBL-2-3-2"
class="td11"> 79.5%         </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-2-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-4-1"
class="td11"> 14 400     (120x120)  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-2-4-2"
class="td11"> 84.5%         </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-2-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-5-1"
class="td11"> 25 600     (160x160)  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-2-5-2"
class="td11"> 85.7%         </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-2-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-6-1"
class="td11"> 65 536     (256x256)  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-2-6-2"
class="td11"> 86.4%         </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-2-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-2-7-1"
class="td11">                  </td></tr></table></div>
</div><div class="minipage"><div class="tabular"> <table id="TBL-3" class="tabular"
cellspacing="0" cellpadding="0"
><colgroup id="TBL-3-1g"><col
id="TBL-3-1"></colgroup><colgroup id="TBL-3-2g"><col
id="TBL-3-2"></colgroup><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-3-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-1-1"
class="td11"> Jako&#347;&#263; JPEG  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-1-2"
class="td11"> Skuteczno&#347;&#263;  </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-3-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-2-1"
class="td11"> 10                 </td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-2-2"
class="td11"> 67.3%         </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-3-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-3-1"
class="td11"> 20                 </td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-3-2"
class="td11"> 81.4%         </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-3-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-4-1"
class="td11"> 30                 </td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-4-2"
class="td11"> 83.9%         </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-3-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-5-1"
class="td11"> 50                 </td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-5-2"
class="td11"> 85.5%         </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-3-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-6-1"
class="td11"> 70                 </td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-6-2"
class="td11"> 86.1%         </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-3-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-7-1"
class="td11"> 90                 </td><td  style="white-space:nowrap; text-align:left;" id="TBL-3-7-2"
class="td11"> 86.5%         </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-3-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-8-1"
class="td11">              </td></tr></table></div></div>


   </div><hr class="endfloat" />
   </div>
   <h4 class="subsectionHead"><span class="titlemark">3.2.4   </span> <a
 id="x1-120003.2.4"></a>U&#380;ycie wytrenowanej sieci</h4>
<!--l. 178--><p class="noindent" >W projektowanym systemie zostanie u&#380;yty wytrenowany model <span
class="qx-lmri-12">Keras</span>
<span
class="qx-lmri-12">FaceNet</span>&#x00A0;[<span
class="qx-lmbx-12">taniai-2018</span>], który zosta&#322; wyszkolony na bazie zdj&#281;&#263; dostarczonych
przez MS-Celeb-1M&#x00A0;[<span
class="qx-lmbx-12">microsoft-2020-celeb1m</span>] i udost&#281;pniony przez <span
class="qx-lmri-12">Hiroki</span>
<span
class="qx-lmri-12">Taniai</span>&#x00A0;[<span
class="qx-lmbx-12">taniai-no-date</span>]. Dostarczane zdj&#281;cia twarzy powinny by&#263; kolorowe, w formacie
RGB oraz o rozmiarach 160 pikseli na 160 pikseli&#x00A0;[<span
class="qx-lmbx-12">brownlee-2019</span>].
<!--l. 185--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">3.3   </span> <a
 id="x1-130003.3"></a>Kadrowanie i standaryzacja</h3>
<!--l. 187--><p class="noindent" >Do przetwarzania plików graficznych zostanie wykorzystana biblioteka <span
class="qx-lmri-12">PILLOW</span>
napisana w j&#281;zyku python. Biblioteka wspiera wiele formatów graficznych, w tym te
najpopularniejsze jak <span
class="qx-lmri-12">PNG</span>, <span
class="qx-lmri-12">GIF</span>, <span
class="qx-lmri-12">JPEG </span>oraz BMP&#x00A0;[<span
class="qx-lmbx-12">pillow&#x02D9;doc</span>], dzi&#281;ki czemu nie b&#281;dzie
wymagane, aby u&#380;ytkownik sam konwertowa&#322; plików graficznych do odpowiedniego
formatu. Biblioteka <span
class="qx-lmri-12">PILLOW </span>zostanie równie&#380; wykorzystana do wycinania zdj&#281;cia
twarzy.


<!--l. 196--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">3.4   </span> <a
 id="x1-140003.4"></a>Klasyfikator SVM</h3>
<!--l. 198--><p class="noindent" >Ostatnim krokiem w systemie jest dokonanie klasyfikacji wygenerowanego wektora cech,
czyli okre&#347;lenie, do jakiej grupy nale&#380;y wektor na podstawie próbek ucz&#261;cych. Innymi
s&#322;owy, etap ten polega na zwróceniu informacji, do kogo najbardziej pasuje przes&#322;ane
zdj&#281;cie, opieraj&#261;c si&#281; na fotografiach dost&#281;pnych w systemie.
<!--l. 203--><p class="indent" >   Jednym z szeroko stosowanych algorytmów klasyfikacji jest <span
class="qx-lmbx-12">maszyna wektorów</span>
<span
class="qx-lmbx-12">no&#347;nych </span>(ang. support vector machine &#8212; SVM). Klasyfikator ten konstruuje
hiperp&#322;aszczyzn&#281; lub ich zbiór w przestrzeni wielowymiarowej, na podstawie otrzymanych
próbek, która oddziela poszczególne klasy. Optymalizowanie modelu SVM polega na
maksymalizacji marginesu pomi&#281;dzy p&#322;aszczyzn&#261; a poszczególnymi klasami, poniewa&#380; na
ogó&#322; nim wi&#281;kszy margines, tym mniejszy jest b&#322;&#261;d generalizacji&#x00A0;[<span
class="qx-lmbx-12">hastie2009elements</span>].
Koncepcja klasyfikatora zosta&#322;a zaprezentowana na rysunku&#x00A0;<a
href="#x1-14001r4">3.4<!--tex4ht:ref: fig:svm --></a>.
<!--l. 211--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-14001r4"></a>


<!--l. 213--><p class="noindent" ><img
        src="../images/smv.png" alt="PIC"
        width="426" height="426" >
<a
 id="x1-14002"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;3.4:  </span><span
class="content">Model  maszyny  wektorów  no&#347;nych.  Po  lewej  mo&#380;liwe  po&#322;o&#380;enia
hiperp&#322;aszczyzny, po prawej zoptymalizowany model SVM. </span></div><!--tex4ht:label?: x1-14001r3.4 -->
<!--l. 218--><p class="noindent" >&#377;ród&#322;o: [<span
class="qx-lmbx-12">raschka2017python</span>]


<!--l. 220--><p class="indent" >   </div><hr class="endfigure">


   <h4 class="subsectionHead"><span class="titlemark">3.4.1   </span> <a
 id="x1-150003.4.1"></a>Margines twardy</h4>
<!--l. 226--><p class="noindent" >Je&#347;li dane ucz&#261;ce s&#261; liniowo separowalne, to mo&#380;na wybra&#263; dwie równoleg&#322;e
hiperp&#322;aszczyzny, które oddzielaj&#261; dwie klasy danych, tak aby odleg&#322;o&#347;&#263; mi&#281;dzy nimi by&#322;a
maksymalna. Obszar ograniczony przez te dwie hiperp&#322;aszczyzny nazywany jest
&#8220;marginesem&#8221;, a hiperp&#322;aszczyzna maksymalnego marginesu to hiperp&#322;aszczyzna le&#380;&#261;ca w
po&#322;owie odleg&#322;o&#347;ci mi&#281;dzy nimi. Problem optymalizacji algorytmu zosta&#322; przedstawiony
równaniem&#x00A0;<a
href="#x1-15001r2">3.2<!--tex4ht:ref: eq:hard_margin --></a>&#x00A0;[<span
class="qx-lmbx-12">raschka2017python</span>]. Lew&#261; stron&#261; tego równania jest odleg&#322;o&#347;&#263;
pomi&#281;dzy hiperp&#322;aszczyzn&#261; &#8220;pozytywn&#261;&#8221; a &#8220;negatywn&#261;&#8221;, zatem, w celu maksymalizacji
marginesu, nale&#380;y zmaksymalizowa&#263; <img
src="praca_magisterska1x.png" alt="-2--
||w||"  class="frac" align="middle"> lub minimalizowa&#263; odwrotno&#347;&#263; wyra&#380;enia, czyli
<img
src="praca_magisterska2x.png" alt="1
2"  class="frac" align="middle"><span
class="lmsy-10x-x-120">||</span><span
class="lmmi-12">w</span><span
class="lmsy-10x-x-120">||</span><sup><span
class="rm-lmr-8">2</span></sup>.
   <table
class="equation"><tr><td><a
 id="x1-15001r2"></a>
   <center class="math-display" >
<img
src="praca_magisterska3x.png" alt="      wT-(xpoz --xneg)   -2---
            ||w ||      =  ||w ||

gdzie:

    w  -wektor  normalny  do granicy decyzyjno&#347;ci

  xpoz -&#8220;pozytywny  &#8221; wektor no&#347;ny

  xneg -&#8220;negatywny  &#8221; wektor no&#347;ny
" class="math-display" ></center></td><td class="equation-label">(3.2)</td></tr></table>
<!--l. 246--><p class="nopar" >
<!--l. 249--><p class="indent" >   W przypadku danych liniowo separowalnych równanie&#x00A0;<a
href="#x1-15001r2">3.2<!--tex4ht:ref: eq:hard_margin --></a> musi spe&#322;nia&#263;
warunki przedstawione w równaniu&#x00A0;<a
href="#x1-15002r3">3.3<!--tex4ht:ref: eq:hard_margin_class --></a>&#x00A0;[<span
class="qx-lmbx-12">raschka2017python</span>]. Równania te
oznaczaj&#261;, &#380;e wszystkie negatywne próbki powinny wyl&#261;dowa&#263; po stronie negatywnej
hiperp&#322;aszczyzny, a wszystkie próbki pozytywne po stronie hiperp&#322;aszczyzny
pozytywnej.
   <table
class="equation"><tr><td><a
 id="x1-15002r3"></a>


   <center class="math-display" >
<img
src="praca_magisterska4x.png" alt="w0 + wT x (i) &#x2265; 1                                 je&#347;li y(i) = 1
       T  (i)                                           (i)
w0 + w  x   &#x2264;  - 1                               je&#347;li y   = - 1

       dla i = 1...N
     gdzie:

          N - liczba próbek

w0 + wT x (i)- odleg&#322;o&#347;&#263; od granicy decyzyjno&#347;ci
" class="math-display" ></center></td><td class="equation-label">(3.3)</td></tr></table>
<!--l. 268--><p class="nopar" >


<!--l. 272--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">3.4.2   </span> <a
 id="x1-160003.4.2"></a>Margines mi&#281;kki</h4>
<!--l. 274--><p class="noindent" >W przypadku, gdy dane nie s&#261; liniowo separowalne (rysunek&#x00A0;<a
href="#x1-16002r5">3.5<!--tex4ht:ref: fig:sofm_margin --></a>) wprowadza
si&#281; dodatkow&#261; zmienn&#261; <span
class="lmmi-12">&#x03BE;</span>. Motywacj&#261; wprowadzenia tej zmiennej jest potrzeba
&#8220;uelastycznienia&#8221; liniowych ogranicze&#324; (równanie&#x00A0;<a
href="#x1-15002r3">3.3<!--tex4ht:ref: eq:hard_margin_class --></a>) podczas analizowania nieliniowo
rozdzielnych danych, co pozwala na uzyskanie zbie&#380;no&#347;ci algorytmu ucz&#261;cego w obecno&#347;ci
nieprawid&#322;owych klasyfikacji podczas stosowania odpowiedniej funkcji strat. Po
wprowadzeniu zmiennej <span
class="lmmi-12">&#x03BE; </span>do równiania&#x00A0;<a
href="#x1-15002r3">3.3<!--tex4ht:ref: eq:hard_margin_class --></a>, równanie to przybiera posta&#263; opisan&#261;
wzorami&#x00A0;<a
href="#x1-16001r4">3.4<!--tex4ht:ref: eq:soft_margin --></a>&#x00A0;[<span
class="qx-lmbx-12">raschka2017python</span>].
   <table
class="equation"><tr><td><a
 id="x1-16001r4"></a>
   <center class="math-display" >
<img
src="praca_magisterska5x.png" alt="       T  (i)        (i)                                           (i)
w0 +  w x   &#x2265;  1 - &#x03BE;                                       je&#347;li y   = 1
w0 +  wTx (i) &#x2264; - 1 + &#x03BE;(i)                                  je&#347;li y(i) = - 1

       dla i = 1...N

      gdzie:

          N - liczba próbek

           &#x03BE;- warto&#347;&#263; przesuni&#281;cia granicy przynale &#380;no&#347;ci
w  +  wTx (i)- odleg&#322;o&#347;&#263; od granicy decyzyjno&#347;ci
  0
" class="math-display" ></center></td><td class="equation-label">(3.4)</td></tr></table>
<!--l. 295--><p class="nopar" >
<!--l. 299--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-16002r5"></a>


<!--l. 301--><p class="noindent" > <img
        src="../images/soft-margin.drawio-.png" alt="PIC"
        width="170" height="170" >
<a
 id="x1-16003"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;3.5: </span><span
class="content">Przyk&#322;ad próbek nieliniowo rozdzielnych </span></div><!--tex4ht:label?: x1-16002r3.4 -->
<!--l. 304--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 305--><p class="indent" >   </div><hr class="endfigure">


<!--l. 309--><p class="noindent" >Nowym celem optymalizacji staje wtedy si&#281; równanie&#x00A0;<a
href="#x1-16004r5">3.5<!--tex4ht:ref: eq:hard_svm_min_problem --></a>&#x00A0;[<span
class="qx-lmbx-12">raschka2017python</span>]. Za
pomoc&#261; zmiennej <span
class="lmmi-12">C </span>kontroluje si&#281; wag&#281; kary za niew&#322;a&#347;ciw&#261; klasyfikacj&#281;. Du&#380;a warto&#347;&#263;
parametru <span
class="lmmi-12">C </span>odpowiada wysokim karom za b&#322;&#281;dy, z kolei przy niskich warto&#347;ciach kara
nie b&#281;dzie mocno wp&#322;ywa&#263; na szeroko&#347;&#263; marginesu. Dzi&#281;ki temu parametrowi jest si&#281; w
stanie regulowa&#263; kompromis pomi&#281;dzy obci&#261;&#380;eniem a wariancj&#261;&#x00A0;[<span
class="qx-lmbx-12">raschka2017python</span>]
(rysunek&#x00A0;<a
href="#x1-16005r6">3.6<!--tex4ht:ref: fig:wplyw_c_na_svm --></a>).
   <table
class="equation"><tr><td><a
 id="x1-16004r5"></a>
   <center class="math-display" >
<img
src="praca_magisterska6x.png" alt="      1          &#x2211;N
      -||w ||2 + C (   &#x03BE;(i))
      2            i
gdzie:

     C  -mno  &#380;nik kary za z&#322;&#261; klasyfikacj&#281;
" class="math-display" ></center></td><td class="equation-label">(3.5)</td></tr></table>
<!--l. 323--><p class="nopar" >
<!--l. 329--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-16005r6"></a>


<!--l. 331--><p class="noindent" ><img
        src="../images/wplyw_c_na_svm.png" alt="PIC"
        width="298" height="298" >
<a
 id="x1-16006"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;3.6: </span><span
class="content">Wp&#322;yw zmiennej C na szeroko&#347;&#263; marginesu </span></div><!--tex4ht:label?: x1-16005r3.4 -->
<!--l. 333--><p class="noindent" >&#377;ród&#322;o: [<span
class="qx-lmbx-12">raschka2017python</span>]


<!--l. 335--><p class="indent" >   </div><hr class="endfigure">


   <h4 class="subsectionHead"><span class="titlemark">3.4.3   </span> <a
 id="x1-170003.4.3"></a>Klasyfikacja nieliniowa</h4>
<!--l. 341--><p class="noindent" >W przypadku, gdy dostarczone dane nie s&#261; separowalne za pomoc&#261; hiperp&#322;aszczyzny w <span
class="lmmi-12">N</span>
wymiarach (rysunek&#x00A0;<a
href="#x1-17002r7">3.7<!--tex4ht:ref: fig:dane_nie_separowalne_liniowo --></a>) wprowadza si&#281; dodatkowe wymiary za pomoc&#261; funkcji
mapuj&#261;cej <span
class="lmmi-12">&#x03D5;</span>. Dodatkowe wymiary wprowadza si&#281; tak d&#322;ugo, a&#380; dane stan&#261; si&#281; liniowo
separowalne. Przyk&#322;adowo, w celu wyznaczenia granicy decyzyjno&#347;ci danych
przedstawionych na rysunku&#x00A0;<a
href="#x1-17002r7">3.7<!--tex4ht:ref: fig:dane_nie_separowalne_liniowo --></a>, funkcja mapuj&#261;ca, za pomoc&#261; której b&#281;dzie mo&#380;liwe
wyznaczenie hiperp&#322;aszczyzny, zosta&#322;a przedstawiona równaniem&#x00A0;<a
href="#x1-17001r6">3.6<!--tex4ht:ref: eq:przykladowy_kernel --></a>. Rezultat
mapowania danych z rysunku&#x00A0;<a
href="#x1-17002r7">3.7<!--tex4ht:ref: fig:dane_nie_separowalne_liniowo --></a> przez funkcj&#281;&#x00A0;<a
href="#x1-17001r6">3.6<!--tex4ht:ref: eq:przykladowy_kernel --></a> zosta&#322; przedstawiony na rysunku&#x00A0;<a
href="#x1-17004r8">3.8<!--tex4ht:ref: fig:wyniki_mapowan --></a>.
Po wykonaniu mapowania oraz wyznaczeniu hiperp&#322;aszczyzny dokonuje si&#281; rzutowania do
pierwotnej przestrzeni cech (<span
class="lmmi-12">&#x03D5;</span><sup><span
class="lmsy8-">-</span><span
class="rm-lmr-8">1</span></sup>).
   <table
class="equation"><tr><td><a
 id="x1-17001r6"></a>
   <center class="math-display" >
<img
src="praca_magisterska7x.png" alt="                                2    2
&#x03D5;(x1,x2) = (z1,z2,z3) = (x1,x2,x1 + x2)
" class="math-display" ></center></td><td class="equation-label">(3.6)</td></tr></table>
<!--l. 358--><p class="nopar" >
<!--l. 360--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-17002r7"></a>


<!--l. 362--><p class="noindent" ><img
        src="../images/dane_nie_separowalne_liniowo.png" alt="PIC"
        width="128" height="128" >
<a
 id="x1-17003"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;3.7: </span><span
class="content">Zestaw danych nie separowalnych liniowo </span></div><!--tex4ht:label?: x1-17002r3.4 -->
<!--l. 364--><p class="noindent" >&#377;ród&#322;o: [<span
class="qx-lmbx-12">raschka2017python</span>]


<!--l. 366--><p class="indent" >   </div><hr class="endfigure">
<!--l. 368--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-17004r8"></a>


<!--l. 370--><p class="noindent" ><img
        src="../images/wyniki_mapowan.png" alt="PIC"
        width="426" height="426" >
<a
 id="x1-17005"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;3.8: </span><span
class="content">Sposób wyznaczania nieliniowej granicy decyzyjno&#347;ci </span></div><!--tex4ht:label?: x1-17004r3.4 -->
<!--l. 372--><p class="noindent" >&#377;ród&#322;o: [<span
class="qx-lmbx-12">raschka2017python</span>]


<!--l. 374--><p class="indent" >   </div><hr class="endfigure">


   <h4 class="subsectionHead"><span class="titlemark">3.4.4   </span> <a
 id="x1-180003.4.4"></a>Klasyfikacja wieloklasowa</h4>
<!--l. 380--><p class="noindent" >Wszystkie opisane wy&#380;ej przypadki dotycz&#261; problemów binarnych, czyli takich
gdzie dostarczona próbka nale&#380;y do jednej z dwóch klas. W zwi&#261;zku z tym,
&#380;e SVM obs&#322;uguje tylko klasyfikacj&#281; binarn&#261;, dlatego w przypadku gdy dana
próbka mo&#380;e nale&#380;e&#263; do jeden z <span
class="lmmi-12">N </span>klas (klasyfikacja wieloklasowa) dokonuje
si&#281; rozbicia jednego problemu klasyfikacji wieloklasowej na wiele problemów
klasyfikacji binarnej. W tym celu stosuje si&#281; jedn&#261; z dwóch strategii - jeden
kontra jeden (ang. one vs one &#8212; OvO) lub jeden przeciwko wszystkim (ang.
one vs all &#8212; OvA). Obie te strategie zosta&#322;y przedstawione na rysunku&#x00A0;<a
href="#x1-18001r9">3.9<!--tex4ht:ref: fig:ovr --></a>
oraz&#x00A0;<a
href="#x1-18003r10">3.10<!--tex4ht:ref: fig:ovo --></a>.
<!--l. 390--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-18001r9"></a>


<!--l. 392--><p class="noindent" > <img
        src="../images/ovr-.png" alt="PIC"
        width="298" height="298" >
<a
 id="x1-18002"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;3.9: </span><span
class="content">Strategia jeden przeciwko wszystkim </span></div><!--tex4ht:label?: x1-18001r3.4 -->
<!--l. 395--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 396--><p class="indent" >   </div><hr class="endfigure">
<!--l. 398--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-18003r10"></a>


<!--l. 400--><p class="noindent" > <img
        src="../images/ovo-.png" alt="PIC"
        width="298" height="298" >
<a
 id="x1-18004"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;3.10: </span><span
class="content">Strategia jeden kontra jeden </span></div><!--tex4ht:label?: x1-18003r3.4 -->
<!--l. 403--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 404--><p class="indent" >   </div><hr class="endfigure">


   <h3 class="sectionHead"><span class="titlemark">3.5   </span> <a
 id="x1-190003.5"></a>Obs&#322;uga systemu</h3>
<!--l. 411--><p class="noindent" >Ca&#322;o&#347;&#263; zaprojektowanego systemu ma by&#263; dost&#281;pna z przegl&#261;darki internetowej. Aby
sprosta&#263; temu wymaganiu, nale&#380;y napisa&#263; us&#322;ug&#281;, która jest w stanie obs&#322;ugiwa&#263;
po&#322;&#261;czenia HTTP (ang. Hypertext Transfer Protocol). Z powodu, &#380;e narz&#281;dzia do
wykrywania twarzy, obróbki zdj&#281;&#263; oraz FaceNet s&#261; udost&#281;pnione w j&#281;zyku python,
program zostanie równie&#380; napisany w tym j&#281;zyku. Oprócz samej strony internetowej
potrzebna jest równie&#380; baza danych, w której b&#281;d&#261; przechowywane informacje o
dost&#281;pnych zdj&#281;ciach. Same zdj&#281;cia b&#281;d&#261; przechowywane na serwerze plików. Sporym
u&#322;atwieniem b&#281;dzie równie&#380; panel umo&#380;liwiaj&#261;cy zarz&#261;dzanie dost&#281;pnymi zdj&#281;ciami w
systemie.
<!--l. 421--><p class="indent" >   Narz&#281;dziem, które spe&#322;ni wy&#380;ej postawione wymagania jest platforma programistyczna
<span
class="qx-lmri-12">Django</span>, która umo&#380;liwia w &#322;atwy sposób zarz&#261;dzanie baz&#261; danych za pomoc&#261; mapowania
obiektowo-relacyjnego, pozwala na zarz&#261;dzanie danymi dost&#281;pnymi w bazie danych
poprzez panel administratora, dost&#281;pny z poziomu przegl&#261;darki oraz co najwa&#380;niejsze,
jest napisana w j&#281;zyku python&#x00A0;[<span
class="qx-lmbx-12">djangodoc</span>].






   <h2 class="chapterHead"><span class="titlemark">Rozdzia&#322;&#x00A0;4</span><br /><a
 id="x1-200004"></a>Implementacja systemu</h2>
   <h3 class="sectionHead"><span class="titlemark">4.1   </span> <a
 id="x1-210004.1"></a>Kadrowanie twarzy</h3>
<!--l. 6--><p class="noindent" >Zdj&#281;cia, które zostan&#261; przes&#322;ane na serwer, nale&#380;y w pierwszej kolejno&#347;ci odpowiednio
przygotowa&#263;. W tym celu zosta&#322;a wykorzystana wcze&#347;niej wspomniana biblioteka
PILLOW, która ma za zadanie wykona&#263; przekszta&#322;cenie otrzymanego pliku do tablicy
pikseli. Otrzymana tablica nast&#281;pnie trafia do sieci MTCNN, która zwraca informacje
na temat wykrytych twarzy, po czym nast&#281;puje wycinanie fragmentu zdj&#281;cia
przedstawiaj&#261;cego sam&#261; twarz. Je&#380;eli nie zostan&#261; znalezione &#380;adne twarze, zostanie
wygenerowany wyj&#261;tek.
<!--l. 14--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">4.2   </span> <a
 id="x1-220004.2"></a>Generowanie wektora cech</h3>
<!--l. 16--><p class="noindent" >Po wykadrowaniu twarzy, kolejnym krokiem jest wygenerowanie wektora cech.
Odpowiednio przygotowana wcze&#347;niej tablica pikseli jest standaryzowana, poniewa&#380;
wymaga tego u&#380;ywana implementacja architektury FaceNet, a nast&#281;pnie wykonywana
jest predykcja. Jako wynik dzia&#322;a funkcji zwracany jest 128 wymiarowy wektor
cech.


<!--l. 25--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">4.3   </span> <a
 id="x1-230004.3"></a>Ocena podobie&#324;stwa twarzy</h3>
<!--l. 27--><p class="noindent" >FaceNet zosta&#322; nauczony tak, aby mapowa&#263; zdj&#281;cia twarzy do n-wymiarowych
wektorów, gdzie odleg&#322;o&#347;ci mierzone za pomoc&#261; metryki euklidesowej odpowiadaj&#261;
mierze podobie&#324;stwa twarzy. Oznacza to, &#380;e je&#380;eli odleg&#322;o&#347;&#263; pomi&#281;dzy dwoma
punktami w przestrzeni jest wzgl&#281;dnie ma&#322;a, to jest wysoce prawdopodobne, &#380;e
zdj&#281;cia twarzy przedstawiaj&#261; t&#281; sam&#261; osob&#281;. Maj&#261;c to na uwadze, mo&#380;na znale&#378;&#263;
odleg&#322;o&#347;&#263;, poni&#380;ej której zosta&#322;oby uznane, &#380;e zdj&#281;cia dotycz&#261; tej samej osoby
(rysunek&#x00A0;<a
href="#x1-23001r1">4.1<!--tex4ht:ref: fig:szukanie_progu --></a>).
<!--l. 34--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-23001r1"></a>


<!--l. 36--><p class="noindent" > <img
        src="../images/szukanie_progu-.png" alt="PIC"
        width="426" height="426" >
<a
 id="x1-23002"></a>
<br />  <div class="caption"
><span class="id">Rysunek&#x00A0;4.1:  </span><span
class="content">Wizualizacja  szukanego  progu  podobie&#324;stwa.  Je&#380;eli  odleg&#322;o&#347;&#263;
pomi&#281;dzy punktami jest zmniejsza ni&#380; warto&#347;&#263; &#8220;x&#8221; to program powinien uzna&#263;, &#380;e
wektory opisuj&#261; t&#281; sam&#261; osob&#281;. </span></div><!--tex4ht:label?: x1-23001r4.3 -->
<!--l. 40--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 41--><p class="indent" >   </div><hr class="endfigure">


   <h4 class="subsectionHead"><span class="titlemark">4.3.1   </span> <a
 id="x1-240004.3.1"></a>Poszukiwanie odleg&#322;o&#347;ci</h4>
<!--l. 47--><p class="noindent" >Do poszukiwania warto&#347;ci progu zosta&#322;o wykorzystanych 5000 losowo wybranych
zdj&#281;&#263;, przedstawiaj&#261;cych 500 ró&#380;nych osób, po 10 zdj&#281;&#263; na osob&#281;, z bazy
CelebA&#x00A0;[<span
class="qx-lmbx-12">liu2015faceattributes</span>]. Na ka&#380;dym zdj&#281;ciu zosta&#322;o nast&#281;pnie wykonane
kadrowanie twarzy oraz generowanie wektora cech. Ostatnim elementem by&#322;o zbadanie
odleg&#322;o&#347;ci pomi&#281;dzy wszystkimi wektorami tych samych oraz ró&#380;nych osób. Ca&#322;o&#347;&#263;
badania mo&#380;na podsumowa&#263; w nast&#281;puj&#261;cych krokach:
      <ol  class="enumerate1" >
      <li
  class="enumerate" id="x1-24002x1">wygenerowania wektora cech dla ka&#380;dego z dost&#281;pnych zdj&#281;&#263;,
      </li>
      <li
  class="enumerate" id="x1-24004x2">wybranie wektora cech ze zbioru,
      </li>
      <li
  class="enumerate" id="x1-24006x3">zmierzenie odleg&#322;o&#347;ci pomi&#281;dzy wybranym wektorem i wszystkimi pozosta&#322;ymi
      wektorami z uwzgl&#281;dnieniem, czy wektory cech reprezentuj&#261; t&#281; sam&#261; osob&#281;,
      czy dwie ró&#380;ne osoby,
      </li>
      <li
  class="enumerate" id="x1-24008x4">powrót  do  kroku  drugiego  do  momentu,  a&#380;  zostan&#261;  zbadane  wszystkie
      odgleg&#322;o&#347;ci (ka&#380;dy z ka&#380;dym).</li></ol>
<!--l. 60--><p class="noindent" >Wyniki przeprowadzonych kroków zosta&#322;y przedstawione w postaci histogramów na
rysunku&#x00A0;<a
href="#x1-24009r2">4.2<!--tex4ht:ref: fig:porownanie_histogramow_odleglosci --></a>.
<!--l. 62--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-24009r2"></a>


<!--l. 64--><p class="noindent" ><img
        src="../images/porownanie_histogramow_odleglosci.png" alt="PIC"
        width="426" height="426" >
<a
 id="x1-24010"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;4.2: </span><span
class="content">Porównanie histogramów odleg&#322;o&#347;ci pomi&#281;dzy wektorami twarzy tych
samych oraz ró&#380;nych osób </span></div><!--tex4ht:label?: x1-24009r4.3 -->
<!--l. 67--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 68--><p class="indent" >   </div><hr class="endfigure">


<!--l. 72--><p class="indent" >   Na podstawie histogramów (rysunek&#x00A0;<a
href="#x1-24009r2">4.2<!--tex4ht:ref: fig:porownanie_histogramow_odleglosci --></a>) mo&#380;na zauwa&#380;y&#263;, &#380;e nie istnieje taka
warto&#347;&#263;, która jest w stanie odseparowa&#263; przedstawione zbiory. Nale&#380;y jednak zwróci&#263;
uwag&#281; na to, &#380;e w badaniu zosta&#322;y wzi&#281;te odleg&#322;o&#347;ci pomi&#281;dzy <span
class="qx-lmbx-12">ka</span><span
class="qx-lmbx-12">&#380;dym </span>zdj&#281;ciem z grupy.
Przy ocenie podobie&#324;stwa pomi&#281;dzy twarzami nie ma potrzeby patrzenia na
odleg&#322;o&#347;ci na ca&#322;ym zbiorze zdj&#281;&#263;. Po wygenerowaniu wektora cech dla danego
zdj&#281;cia interesuj&#261;cy jest tylko ten wektor, który le&#380;y <span
class="qx-lmbx-12">najbli</span><span
class="qx-lmbx-12">&#380;ej </span>wygenerowanego
(rysunek&#x00A0;<a
href="#x1-24011r3">4.3<!--tex4ht:ref: fig:najmniejsze --></a>).
<!--l. 79--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-24011r3"></a>


<!--l. 81--><p class="noindent" > <img
        src="../images/dlaczego_najmniejsze-.png" alt="PIC"
        width="426" height="426" >
<a
 id="x1-24012"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;4.3: </span><span
class="content">Schemat obrazuj&#261;cy najbli&#380;sz&#261; odleg&#322;o&#347;&#263; pomi&#281;dzy nowym wektorem
a zbiorem. Na czerwono zosta&#322;y oznaczone odleg&#322;o&#347;ci do dalszych wektorów. Na
zielono zosta&#322;a oznaczona odleg&#322;o&#347;&#263; do najbli&#380;szego wektora i to wzgl&#281;dem niego
system powinien ocenia&#263; podobie&#324;stwo. </span></div><!--tex4ht:label?: x1-24011r4.3 -->
<!--l. 87--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 88--><p class="indent" >   </div><hr class="endfigure">


<!--l. 92--><p class="indent" >   Bior&#261; pod uwag&#281; opisany problem, wy&#380;ej opisane badanie zosta&#322;o powtórzone, jednak
w tym przypadku zosta&#322;y zapisane tylko odleg&#322;o&#347;&#263; do najbli&#380;szego wektora. Ca&#322;o&#347;&#263; zatem
mo&#380;na podsumowa&#263; w nast&#281;puj&#261;cych krokach:
      <ol  class="enumerate1" >
      <li
  class="enumerate" id="x1-24014x1">wygenerowania wektora cech dla ka&#380;dego z dost&#281;pnych zdj&#281;&#263;,
      </li>
      <li
  class="enumerate" id="x1-24016x2">wybranie wektora cech ze zbioru,
      </li>
      <li
  class="enumerate" id="x1-24018x3">znalezienie  wektora,  który  le&#380;y  najbli&#380;ej  wzgl&#281;dem  wybranego  i  zapisanie
      odleg&#322;o&#347;ci z uwzgl&#281;dnieniem czy znaleziony wektor reprezentuje t&#281; sam&#261; osob&#281;,
      </li>
      <li
  class="enumerate" id="x1-24020x4">powrót do kroku drugiego do momentu, a&#380; zostan&#261; wybrane wszystkie wektory.</li></ol>
<!--l. 102--><p class="noindent" >Wyniki powtórzonego badania zosta&#322;y ponownie przedstawione w postaci histogramów na
rysunku&#x00A0;<a
href="#x1-24021r4">4.4<!--tex4ht:ref: fig:wykres_najmniejszych_odleglosc_wspolny --></a>.
<!--l. 105--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-24021r4"></a>


<!--l. 107--><p class="noindent" ><img
        src="../images/wykres_najmniejszych_odleglosc_wspolny.png" alt="PIC"
        width="426" height="426" >
<a
 id="x1-24022"></a>
<br />  <div class="caption"
><span class="id">Rysunek&#x00A0;4.4:   </span><span
class="content">Porównanie   histogramów   najmniejszych   odleg&#322;o&#347;ci   pomi&#281;dzy
zdj&#281;ciami twarzy tych samych oraz ró&#380;nych osób. </span></div><!--tex4ht:label?: x1-24021r4.3 -->
<!--l. 113--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 114--><p class="indent" >   </div><hr class="endfigure">


<!--l. 118--><p class="indent" >   Z histogramów (rysunek&#x00A0;<a
href="#x1-24021r4">4.4<!--tex4ht:ref: fig:wykres_najmniejszych_odleglosc_wspolny --></a>) wykonanego badania równie&#380; wynika, &#380;e nie istnieje
taka warto&#347;&#263;, która b&#281;dzie w stanie odseparowa&#263; przedstawione zbiory. Konsekwencj&#261; tego
jest, &#380;e dla dowolnego &#8220;x&#8221; b&#281;d&#261; istnie&#263; przypadki, dla których zdj&#281;cia b&#322;&#281;dnie zostan&#261;
uznane, &#380;e przedstawiaj&#261; t&#281; sam&#261; osob&#281;. Nale&#380;y zatem znale&#378;&#263; tak&#261; warto&#347;&#263; &#8220;x&#8221;, dla
której walidator, czyli funkcja oceniaj&#261;ca, czy podane wektory dotycz&#261; tej samej osoby
b&#281;dzie mia&#322; najwi&#281;ksz&#261; skuteczno&#347;&#263;. Przedzia&#322;, w jakim nale&#380;y spodziewa&#263; si&#281; najwi&#281;kszej
skuteczno&#347;ci, powinien (jak wynika z rysunku&#x00A0;<a
href="#x1-24021r4">4.4<!--tex4ht:ref: fig:wykres_najmniejszych_odleglosc_wspolny --></a>) znale&#378;&#263; si&#281; w przedziale od 8 do
12, poniewa&#380; na tym odcinku oba histogramy pokrywaj&#261; si&#281; na najwi&#281;kszym
obszarze.
   <h4 class="subsectionHead"><span class="titlemark">4.3.2   </span> <a
 id="x1-250004.3.2"></a>Odleg&#322;o&#347;&#263; o najwi&#281;kszej skuteczno&#347;ci</h4>
<!--l. 131--><p class="noindent" >W celu sprawdzania dla jakiego &#8220;x&#8221; zostanie zmaksymalizowana liczba prawid&#322;owo
sklasyfikowanych twarzy, wspomniany wcze&#347;niej zbiór zdj&#281;&#263;, zosta&#322; podzielony na
dwie grupy. Do pierwszej grupy trafi&#322;y zdj&#281;cia, które zasili&#322;y system i stanowi&#322;y
baz&#281; w weryfikowaniu, czy nowe zdj&#281;cie, które zostanie dostarczone, zostanie
uznane za podobne do jakiego&#347; zdj&#281;cia twarzy, które znajduje si&#281; ju&#380; w systemie.
Do drugiej grupy trafi&#322;y zdj&#281;cia, które podlega&#322;y ocenie przez system, czy owo
zdj&#281;cie jest znane systemowi. Dok&#322;adny podzia&#322; zdj&#281;&#263; zosta&#322; przedstawiony na
rysunku&#x00A0;<a
href="#x1-25001r5">4.5<!--tex4ht:ref: fig:podzial_zdjec --></a>.
<!--l. 151--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-25001r5"></a>


<!--l. 153--><p class="noindent" ><img
        src="../images/podzial_zdjec.png" alt="PIC"
        width="426" height="426" >
<a
 id="x1-25002"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;4.5: </span><span
class="content">Podzia&#322; zdj&#281;&#263; na grupy. Obok ka&#380;dej z grupy widnieje liczba osób
oraz suma wszystkich zdj&#281;&#263; nale&#380;&#261;ca do owej grupy. </span></div><!--tex4ht:label?: x1-25001r4.3 -->
<!--l. 159--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 160--><p class="indent" >   </div><hr class="endfigure">
<!--l. 162--><p class="indent" >   Po podzieleniu zdj&#281;&#263; na grupy kolejnym krokiem jest zbadanie skuteczno&#347;ci oceny
podobie&#324;stwa dla poszczególnych progów z zakresu od 8 do 12. Zakres ten b&#281;dzie
badany z dok&#322;adno&#347;ci&#261; do 0.1. Kroki, jakie zosta&#322;y wykonane w badaniu, s&#261;
nast&#281;puj&#261;ce:
      <ol  class="enumerate1" >
      <li
  class="enumerate" id="x1-25004x1">wygenerowanie wektora cech dla wszystkich zdj&#281;&#263; z ka&#380;dej grupy,
      </li>
      <li
  class="enumerate" id="x1-25006x2">wgranie wygenerowanych wektorów z grupy &#8220;Zdj&#281;cia do systemu&#8221; do systemu,
      </li>
      <li
  class="enumerate" id="x1-25008x3">pobranie  zdj&#281;&#263;  z  grupy  &#8220;Zdj&#281;cia  nowych  osób&#8221;  i  przepuszczenie  ich  przez
      funkcj&#281; oceniaj&#261;ca podobie&#324;stwo na podstawie wgranych zdj&#281;&#263; do systemu dla
      danego &#8220;x&#8221;,
      </li>
      <li
  class="enumerate" id="x1-25010x4">powtórzenie kroku trzeciego dla zdj&#281;&#263; z grupy &#8220;Zdj&#281;cia znanych osób&#8221;,
      </li>
      <li
  class="enumerate" id="x1-25012x5">potwórzenie kroku trzeciego oraz czwartek dla nowego parametru &#8220;x&#8221;.</li></ol>
<!--l. 177--><p class="indent" >   Dla kroku trzeciego, przy za&#322;o&#380;eniu, &#380;e skuteczno&#347;&#263; oceny podobie&#324;stwa by&#322;a by
stuprocentowa, funkcja powinna zwróci&#263; zawsze warto&#347;&#263; <span
class="qx-lmri-12">False</span>, poniewa&#380; <span
class="qx-lmbx-12">&#380;adna </span>z osób
przedstawiona na zdj&#281;ciach z grupy &#8220;Zdj&#281;cia nowych osób&#8221; nie znajduje si&#281; w systemie.
Dla kroku czwartego, w przeciwie&#324;stwie do kroku trzeciego, funkcja ta powinna zawsze
zwróci&#263; <span
class="qx-lmri-12">True</span>, poniewa&#380; <span
class="qx-lmbx-12">ka</span><span
class="qx-lmbx-12">&#380;da </span>osoba przedstawiona na zdj&#281;ciu z grupy &#8220;Zdj&#281;cia znanych
osób&#8221; znajduje si&#281; w systemie. Niestety z przeprowadzonych wcze&#347;niej bada&#324;
(rysunek&#x00A0;<a
href="#x1-24021r4">4.4<!--tex4ht:ref: fig:wykres_najmniejszych_odleglosc_wspolny --></a>) wynika, &#380;e taki scenariusz nie jest mo&#380;liwy i z tego powodu nale&#380;y znale&#378;&#263;
tak&#261; warto&#347;&#263; parametru &#8220;x&#8221;, dla którego skuteczno&#347;&#263; walidatora oceniaj&#261;cego
podobie&#324;stwo b&#281;dzie maksymalne.
<!--l. 187--><p class="indent" >   Wyniki opisanego wcze&#347;niej badania zosta&#322;y przedstawione na rysunku&#x00A0;<a
href="#x1-25013r6">4.6<!--tex4ht:ref: fig:tranosc_walidatora_per_prog --></a>. Na jego
podstawie mo&#380;na zauwa&#380;y&#263;, &#380;e skuteczno&#347;&#263; walidatora ro&#347;nie wraz ze wzrostem warto&#347;ci
progu a&#380; do momentu osi&#261;gni&#281;cia przez &#8220;x&#8221; warto&#347;ci 10.2 po czym nastepuje spadek. Dla
warto&#347;ci <span
class="qx-lmbx-12">10.2 </span>skuteczno&#347;&#263; funkcji zosta&#322;a oceniona na poziomie <span
class="qx-lmbx-12">92.3%</span>. Obliczona
warto&#347;&#263; oznacza, &#380;e je&#380;eli odleg&#322;o&#347;&#263; pomi&#281;dzy dwoma wektorami, które le&#380;&#261; najbli&#380;ej
siebie, jest mniejsza ni&#380; 10.2 to system uzna, &#380;e owe wektory dotycz&#261; tej samej osoby,
przez co proces b&#281;dzie kontynuowany. W przeciwnym wypadku zostanie wygenerowany


b&#322;&#261;d z informacj&#261;, &#380;e osoba przedstawiona na zdj&#281;ciu, która podlega weryfikacji, nie jest
znana systemowi.
<!--l. 198--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-25013r6"></a>


<!--l. 200--><p class="noindent" ><img
        src="../images/trafnosc_walidator_a_prog.png" alt="PIC"
        width="426" height="426" >
<a
 id="x1-25014"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;4.6:  </span><span
class="content">Skuteczno&#347;&#263;  walidatora  (funkcji  oceniaj&#261;cej,  czy  podane  wektory
dotycz&#261; tej samej osoby) w zale&#380;no&#347;ci od warto&#347;ci progu (parametru &#8220;x&#8221;) </span></div><!--tex4ht:label?: x1-25013r4.3 -->
<!--l. 206--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 207--><p class="indent" >   </div><hr class="endfigure">


   <h3 class="sectionHead"><span class="titlemark">4.4   </span> <a
 id="x1-260004.4"></a>Klasyfikator</h3>
<!--l. 214--><p class="noindent" >Ostatnim krokiem w procesie dzia&#322;aj&#261;cym po stronie serwera (rysunek&#x00A0;<a
href="#x1-5001r1">2.1<!--tex4ht:ref: fig:schemat_blokowy_systemu --></a>) jest
wykonanie klasyfikacji. Na tym etapie wiadome ju&#380; jest, &#380;e wektor cech, który trafi&#322; do
klasyfikatora, reprezentuje osob&#281;, która jest znana systemowi. Jest to bardzo istotna
informacja, poniewa&#380; w przeciwnym wypadku klasyfikator móg&#322;by dokona&#263; klasyfikacji
pomimo tego, &#380;e dana klasa (w tym wypadku osoba) nie istnieje w systemie, co
oznacza&#322;oby zawsze b&#322;&#281;dn&#261; klasyfikacj&#281;.
<!--l. 222--><p class="indent" >   Do wykonywania klasyfikacji zosta&#322; wykorzystany klasyfikator SVM z liniowym
j&#261;drem, z parametrem <span
class="lmmi-12">C </span>równym <span
class="rm-lmr-12">1</span><span
class="lmmi-12">.</span><span
class="rm-lmr-12">0 </span>(równanie&#x00A0;<a
href="#x1-16004r5">3.5<!--tex4ht:ref: eq:hard_svm_min_problem --></a>) oraz strategi&#261; jeden na jednego
(rysunek&#x00A0;<a
href="#x1-18003r10">3.10<!--tex4ht:ref: fig:ovo --></a>). Jego skuteczno&#347;&#263; na opisanym wcze&#347;niej zbiorze (rysunek&#x00A0;<a
href="#x1-25001r5">4.5<!--tex4ht:ref: fig:podzial_zdjec --></a>)
wynios&#322;a <span
class="qx-lmbx-12">96.1%</span>. Z powodu tak wysokiej skuteczno&#347;ci nie by&#322;y testowane inne
klasyfikatory. Implementacja klasyfikatora SVM zosta&#322;a zaczerpni&#281;ta z biblioteki
<span
class="qx-lmri-12">sklearn</span>&#x00A0;[<span
class="qx-lmbx-12">sklearn&#x02D9;api</span>].
<!--l. 230--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">4.5   </span> <a
 id="x1-270004.5"></a>Strona internetowa</h3>
<!--l. 232--><p class="noindent" >Zaprojektowana strona internetowa sk&#322;ada z prostego formularza. Na stronie zosta&#322;
umieszczony przycisk, który umo&#380;liwia wybranie zdj&#281;&#263; z dysku urz&#261;dzenia klienta. Po
wybraniu zdj&#281;cia pojawi si&#281; jego podgl&#261;d, po czym plik jest wysy&#322;any na serwer. Po
uzyskaniu odpowiedzi z serwera zostanie wy&#347;wietlony otrzymany komunikat. Wygl&#261;d
strony zostaw przedstawiony na zdj&#281;ciu&#x00A0;<a
href="#x1-27001r7">4.7<!--tex4ht:ref: fig:ja --></a>.
<!--l. 238--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-27001r7"></a>


<!--l. 240--><p class="noindent" ><div class="adjustbox" id="adjustbox-1"><img
        src="../images/wyglad_frontowa_aplikacji.png" alt="PIC"
        width="425" height="426" ></div>
<a
 id="x1-27002"></a>
 <div class="caption"
><span class="id">Rysunek&#x00A0;4.7: </span><span
class="content">Wygl&#261;d strony internetowej po wybraniu zdj&#281;cia z dysku i uzyskaniu
odpowiedzi z serwera</span></div><!--tex4ht:label?: x1-27001r4.5 -->
&#377;ród&#322;o w&#322;asne


<!--l. 244--><p class="indent" >   </div><hr class="endfigure">






   <h2 class="chapterHead"><span class="titlemark">Rozdzia&#322;&#x00A0;5</span><br /><a
 id="x1-280005"></a>Testowanie systemu</h2>
<!--l. 6--><p class="noindent" >Testowanie napisanej aplikacji b&#281;dzie polega&#263; na r&#281;cznym wprowadzeniu wybranych zdj&#281;&#263;
do systemu. Wszystkie zdj&#281;cia twarzy, u&#380;yte do testowania aplikacji, zosta&#322;y pobrane ze
zbioru CelebA&#x00A0;[<span
class="qx-lmbx-12">microsoft-2020-celeb1m</span>]. Wybrane zdj&#281;cia (rysunek&#x00A0;<a
href="#x1-28001r1">5.1<!--tex4ht:ref: fig:zdjeciadotestow --></a>) zosta&#322;y
podzielone na dwie kategorie:
      <ul class="itemize1">
      <li class="itemize">zdj&#281;cia, które trafi&#261; do systemu jako wzorzec,
      </li>
      <li class="itemize">zdj&#281;cia,  które  zostan&#261;  wykorzystane  w  celu  zbadania  zachowania  oraz
      poprawno&#347;ci komunikatów zwracanych przez system.</li></ul>
<!--l. 16--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-28001r1"></a>


<!--l. 18--><p class="noindent" ><div class="adjustbox" id="adjustbox-2"> <img
        src="../images/zdjeciadotestow-.png" alt="PIC"
        width="425" height="426" ></div>
<a
 id="x1-28002"></a>
 <div class="caption"
><span class="id">Rysunek&#x00A0;5.1:  </span><span
class="content">U&#380;yte  zdj&#281;cia  do  przetestowania  systemu.  Obok  ka&#380;dej  grupy
przedstawiona jest etykieta zdj&#281;&#263;.</span></div><!--tex4ht:label?: x1-28001r5 -->
&#377;ród&#322;o w&#322;asne


<!--l. 22--><p class="indent" >   </div><hr class="endfigure">


   <h3 class="sectionHead"><span class="titlemark">5.1   </span> <a
 id="x1-290005.1"></a>Wgranie zdj&#281;&#263; do systemu</h3>
<!--l. 29--><p class="noindent" >Aplikacja udost&#281;pnia dla administratorów panel, za pomoc&#261; którego jest mo&#380;liwe
wprowadzenie zdj&#281;&#263; do systemu z poziomu przegl&#261;darki. Po zalogowaniu si&#281; zosta&#322;y
wprowadzone wy&#380;ej przedstawione zdj&#281;cia (rysunek&#x00A0;<a
href="#x1-28001r1">5.1<!--tex4ht:ref: fig:zdjeciadotestow --></a>). Dla etykiety oznaczonej
numerem jeden zosta&#322;o wprowadzone jedno zdj&#281;cie, oznaczonej numerem dwa - dwa
zdj&#281;cia przedstawiaj&#261;ce t&#281; sam&#261; osob&#281;, dla kolejnej trzy. Podgl&#261;d wprowadzonych zdj&#281;&#263;
oraz wykadrowanych twarzy zosta&#322; przedstawiony na rysunku&#x00A0;<a
href="#x1-29001r2">5.2<!--tex4ht:ref: fig:po_wprowadzeniu --></a>.
<!--l. 36--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-29001r2"></a>


<!--l. 38--><p class="noindent" ><div class="adjustbox" id="adjustbox-3"> <img
        src="../images/po_wprowadzeniu-.png" alt="PIC"
        width="425" height="426" ></div>
<a
 id="x1-29002"></a>
 <div class="caption"
><span class="id">Rysunek&#x00A0;5.2: </span><span
class="content">Podgl&#261;d wprowadzonych zdj&#281;&#263; do systemu. </span></div><!--tex4ht:label?: x1-29001r5.1 -->
&#377;ród&#322;o w&#322;asne


<!--l. 42--><p class="indent" >   </div><hr class="endfigure">


   <h3 class="sectionHead"><span class="titlemark">5.2   </span> <a
 id="x1-300005.2"></a>Zdj&#281;cie niezawieraj&#261;ce twarzy</h3>
<!--l. 49--><p class="noindent" >Po wys&#322;aniu zdj&#281;cia na serwer, zgodnie ze schematem przedstawionym na rysunku&#x00A0;<a
href="#x1-5001r1">2.1<!--tex4ht:ref: fig:schemat_blokowy_systemu --></a>,
pierwszym krokiem jest kadrowanie twarzy. Informacja na temat samego kadrowania nie
jest znana u&#380;ytkownikowi ko&#324;cowemu, natomiast w przypadku, gdy zostanie wys&#322;ane
zdj&#281;cie niezawieraj&#261;ce twarzy, to u&#380;ytkownik powinien dosta&#263; informacj&#281; zwrotn&#261;. W celu
sprawdzenia, czy funkcjonalno&#347;&#263; zadzia&#322;a prawid&#322;owo, zosta&#322;o wys&#322;ane na serwer zdj&#281;cie,
które zawiera krajobraz. Z powodu, &#380;e na zdj&#281;ciu nie ma przedstawionych &#380;adnych osób,
system powinien zwróci&#263; informacj&#281; o b&#322;&#281;dzie. Wynik testu zosta&#322; pokazany na
rysunku&#x00A0;<a
href="#x1-30001r3">5.3<!--tex4ht:ref: fig:wprowadzona_natura --></a>. Komunikat o braku twarzy zosta&#322; zwrócony, co oznacza, &#380;e system zachowa&#322;
si&#281; poprawnie.
<!--l. 58--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-30001r3"></a>


<!--l. 60--><p class="noindent" ><div class="adjustbox" id="adjustbox-4"><img
        src="../images/wprowadzona_natura.png" alt="PIC"
        width="425" height="426" ></div>
<a
 id="x1-30002"></a>
 <div class="caption"
><span class="id">Rysunek&#x00A0;5.3:  </span><span
class="content">Zachowanie  systemu  po  wprowadzeniu  zdj&#281;cia  niezawieraj&#261;cego
twarzy. </span></div><!--tex4ht:label?: x1-30001r5.2 -->
&#377;ród&#322;o w&#322;asne


<!--l. 64--><p class="indent" >   </div><hr class="endfigure">


   <h3 class="sectionHead"><span class="titlemark">5.3   </span> <a
 id="x1-310005.3"></a>Zdj&#281;cie osoby nieznanej systemowi</h3>
<!--l. 71--><p class="noindent" >Kolejnym krokiem do przetestowania jest sprawdzenie czy system zwróci informacj&#281;, gdy
zostanie wys&#322;ane zdj&#281;cie osoby, która nie zosta&#322;a wcze&#347;niej zaimportowana. Z tego powodu
system powinien zwróci&#263; informacj&#281;, &#380;e nie rozpoznano osoby na zdj&#281;ciu. W tym
celu zosta&#322;y przygotowane zdj&#281;cia m&#281;&#380;czyzn oznaczone etykiet&#261; &#8220;4&#8221; oraz &#8220;5&#8221;
(rysunek&#x00A0;<a
href="#x1-28001r1">5.1<!--tex4ht:ref: fig:zdjeciadotestow --></a>). Wyniki testu zosta&#322;y przedstawione na rysunku&#x00A0;<a
href="#x1-31001r4">5.4<!--tex4ht:ref: fig:rezultat_nieznane --></a>. Dla ka&#380;dego
ze zdj&#281;&#263; zosta&#322; zwrócony komunikat z informacj&#261;, &#380;e nie rozpoznano osoby na
zdj&#281;ciu. Oznacza to, &#380;e system zachowa&#322; si&#281; poprawnie i test mo&#380;na uzna&#263; za
zaliczony.
<!--l. 79--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-31001r4"></a>


<!--l. 81--><p class="noindent" ><div class="adjustbox" id="adjustbox-5"><img
        src="../images/rezultat_nieznane.png" alt="PIC"
        width="425" height="426" ></div>
<a
 id="x1-31002"></a>
 <div class="caption"
><span class="id">Rysunek&#x00A0;5.4: </span><span
class="content">Zachowanie systemu po wybraniu zdj&#281;&#263; nieznanych systemowi </span></div><!--tex4ht:label?: x1-31001r5.3 -->
&#377;ród&#322;o w&#322;asne


<!--l. 85--><p class="indent" >   </div><hr class="endfigure">


   <h3 class="sectionHead"><span class="titlemark">5.4   </span> <a
 id="x1-320005.4"></a>Zdj&#281;cie osoby znanej systemowi</h3>
<!--l. 92--><p class="noindent" >Ostatnim krokiem w procesie jest klasyfikacja, czyli zwrócenie informacji kto zosta&#322;
przedstawiony na przes&#322;anym zdj&#281;ciu. W celu dok&#322;adniejszego przetestowania napisanej
funkcjonalno&#347;ci specjalnie w tym celu zosta&#322;y wgrane do systemu zdj&#281;cia osób o ró&#380;nej
liczbie (rysunek&#x00A0;<a
href="#x1-29001r2">5.2<!--tex4ht:ref: fig:po_wprowadzeniu --></a>), aby sprawdzi&#263;, czy wp&#322;ynie to na otrzymane wyniki. Wyniki testu
zosta&#322;y przedstawione na rysunku&#x00A0;<a
href="#x1-32001r5">5.5<!--tex4ht:ref: fig:rezultat_znane --></a>. Komunikaty zwrócone przez system dla
zdj&#281;&#263; reprezentuj&#261;cych etykiety &#8220;2&#8221; oraz &#8220;3&#8221; s&#261; poprawne. Dla jednego ze zdj&#281;&#263;
przedstawiaj&#261;cych osob&#281; o etykiecie &#8220;1&#8221; system zwróci&#322; informacje, &#380;e nie rozpoznano
osoby na zdj&#281;ciu. <span
class="qx-lmbx-12">Najprawdopodobniej </span>spowodowane jest to tym, &#380;e w systemie
znajduje si&#281; tylko <span
class="qx-lmbx-12">jedno </span>zdj&#281;cie reprezentuj&#261;ce etykiet&#281; &#8220;1&#8221; przedstawiaj&#261;ce
kobiet&#281; o ciemnym kolorze w&#322;osów, a zdj&#281;cie, dla którego system zwróci&#322; b&#322;&#281;dny
komunikat, przedstawia t&#281; sam&#261; kobiet&#281;, tylko &#380;e w innym kolorze w&#322;osów. Dodatkowo
zdj&#281;cie twarzy zrobione jest z inne profilu, cz&#281;&#347;ciowo zas&#322;oni&#281;tego przez w&#322;osy
(rysunek&#x00A0;<a
href="#x1-32003r6">5.6<!--tex4ht:ref: fig:porownanie_etykiety_1 --></a>).
<!--l. 108--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-32001r5"></a>


<!--l. 110--><p class="noindent" ><div class="adjustbox" id="adjustbox-6"><img
        src="../images/rezulat_znane.png" alt="PIC"
        width="425" height="426" ></div>
<a
 id="x1-32002"></a>
 <div class="caption"
><span class="id">Rysunek&#x00A0;5.5: </span><span
class="content">Zwrócone komunikaty przez system dla wybranych zdj&#281;&#263;. Numer obok
komunikatu przedstawia ID osoby na zdj&#281;ciu w systemie. </span></div><!--tex4ht:label?: x1-32001r5.4 -->
&#377;ród&#322;o w&#322;asne


<!--l. 117--><p class="indent" >   </div><hr class="endfigure">
<!--l. 120--><p class="indent" >   <hr class="figure"><div class="figure"
>


<a
 id="x1-32003r6"></a>


<!--l. 122--><p class="noindent" > <img
        src="../images/porownanie_etykiety_1-.png" alt="PIC"
        width="128" height="128" >
<a
 id="x1-32004"></a>
<br /> <div class="caption"
><span class="id">Rysunek&#x00A0;5.6: </span><span
class="content">Porównanie zdj&#281;cia wgranego do systemu (po lewej) ze zdj&#281;ciem &#378;le
zakwalifikowanym przez system (po prawej). </span></div><!--tex4ht:label?: x1-32003r5.4 -->
<!--l. 128--><p class="noindent" >&#377;ród&#322;o w&#322;asne


<!--l. 129--><p class="indent" >   </div><hr class="endfigure">
   <h3 class="sectionHead"><span class="titlemark"><span
class="qx-lmr-10x-x-109">5.5   </span></span> <a
 id="x1-330005.5"></a><span
class="qx-lmr-17x-x-98">Skuteczno&#347;&#263; algorytmu rozpoznawania twarzy</span></h3>
<!--l. 136--><p class="indent" >   Przedstawione dotychczas testy zosta&#322;y wykonane na bardzo ma&#322;ym zbiorze
twarzy. Do aplikacji zosta&#322;o wgranych tylko 6 zdj&#281;&#263; przedstawiaj&#261;cych twarze
3 osób. Wykonanie statystyk na tak ma&#322;ym zbiorze jest niereprezentatywne,
dlatego tym razem zosta&#322; przygotowany zestaw zdj&#281;&#263; sk&#322;adaj&#261;cy si&#281; z 2&#x00A0;000
ró&#380;nych osób, &#322;&#261;cznie 10&#x00A0;000 zdj&#281;&#263; twarzy. Do samej aplikacji, z przygotowanego
zbioru, zosta&#322;o wgranych 5&#x00A0;000 zdj&#281;&#263; twarzy, przedstawiaj&#261;cych 1&#x00A0;000 ró&#380;nych
osób&#x00A0;(po 5 zdj&#281;&#263; na jedn&#261; osob&#281;). Pozosta&#322;e 5&#x00A0;000 zdj&#281;&#263; zosta&#322;o wykorzystanych do
testowania zwracanych komunikatów przez aplikacj&#281;. Wyniki z testów zosta&#322;y
przedstawione w tabeli&#x00A0;<a
href="#x1-33001r1">5.1<!--tex4ht:ref: tab:app_stats --></a>. Z przeprowadzonych testów wynika, &#380;e skuteczno&#347;&#263; aplikacji
wynosi 85,94%, a najbardziej newralgicznym punktem w ca&#322;ym zaprojektowanym
systemie jest walidator, który wygenerowa&#322; a&#380; 639 z 703 wszystkich b&#322;&#281;dnych
komunikatów.
   <div class="table">


<!--l. 149--><p class="indent" >   <a
 id="x1-33001r1"></a><hr class="float"><div class="float"
>


<a
 id="x1-33002"></a>
 <div class="caption"
><span class="id">Tablica&#x00A0;5.1: </span><span
class="content">Wyniki przeprowadzonych testów</span></div><!--tex4ht:label?: x1-33001r5.4 -->
<div class="tabular"> <table id="TBL-4" class="tabular"
cellspacing="0" cellpadding="0"
><colgroup id="TBL-4-1g"><col
id="TBL-4-1"></colgroup><colgroup id="TBL-4-2g"><col
id="TBL-4-2"></colgroup><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-4-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-4-1-1"
class="td11"> <span
class="qx-lmbx-12">Liczba wykonanych testów                   </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-1-2"
class="td11"> 5 000  </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-4-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-4-2-1"
class="td11"> <span
class="qx-lmbx-12">Suma b&#322;&#281;dnych komunikatów                </span></td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-2-2"
class="td11"> 703    </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-4-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-4-3-1"
class="td11"> Liczba zdj&#281;&#263;, na których nie znaleziono twarzy  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-3-2"
class="td11"> 12      </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-4-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-4-4-1"
class="td11"> Liczba b&#322;&#281;dnych komunikatów walidatora        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-4-2"
class="td11"> 639    </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-4-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-4-5-1"
class="td11"> Liczba b&#322;&#281;dnych komunikatów klasyfikatora     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-4-5-2"
class="td11"> 52      </td>
</tr><tr
class="hline"><td><hr></td><td><hr></td></tr><tr
 id="TBL-4-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-4-6-1"
class="td11">                                         </td></tr></table></div>


   </div><hr class="endfloat" />
   </div>






   <h2 class="likechapterHead"><a
 id="x1-340005.5"></a>Podsumowanie</h2>
<a
 id="Q1-1-35"></a>
<!--l. 4--><p class="noindent" >U&#380;ytkownik, dzi&#281;ki temu, &#380;e komunikacja z aplikacj&#261; odbywa si&#281; przez protokó&#322; HTTP,
mo&#380;e po&#322;&#261;czy&#263; si&#281; z serwerem, z dowolnego urz&#261;dzenia maj&#261;cego dost&#281;p do internetu oraz
do przegl&#261;darki internetowej, w celu wys&#322;ania zdj&#281;cia na serwer. Je&#380;eli to urz&#261;dzenie
posiada równie&#380; dost&#281;p do kamery, to jest mo&#380;liwo&#347;&#263; bezpo&#347;redniego wys&#322;ania zrobionego
zdj&#281;cia od razu do systemu. W odpowiedzi na wys&#322;ane zdj&#281;cie zostanie zwrócony
komunikat, zawieraj&#261;cy kim jest osoba przedstawiona na zdj&#281;ciu, pod warunkiem, &#380;e ta
osoba zosta&#322;a wcze&#347;niej wgrana do systemu.
<!--l. 12--><p class="indent" >   Du&#380;ym u&#322;atwieniem w zarz&#261;dzaniu baz&#261; zdj&#281;&#263; jest przygotowany panel
administratora, który pozwala na &#322;atwe zarz&#261;dzanie zdj&#281;ciami, które znajduj&#261; si&#281;
w systemie. Podgl&#261;d aktualnych lub dodawanie kolejnych zdj&#281;&#263; ogranicza si&#281;
tylko do paru klikni&#281;&#263;. Niestety r&#281;czne wysy&#322;anie bardzo du&#380;ej liczby zdj&#281;&#263; za
pomoc&#261; panelu mo&#380;e wymaga&#263; sporo czasu, dlatego w takim przypadku lepiej
jest przygotowa&#263; skrypt, który zaimportuje bezpo&#347;rednio zdj&#281;cia z dysku do
systemu.
<!--l. 18--><p class="indent" >   Próg, po którego przekroczeniu, walidator oceniaj&#261;cy podobie&#324;stwo uzna, &#380;e dane
zdj&#281;cia nie s&#261; do siebie podobne zosta&#322; wyliczony na 10.2. Przy tej warto&#347;ci, na
badanym zbiorze, zosta&#322;a osi&#261;gni&#281;ta maksymalna skuteczno&#347;&#263; wynosz&#261;ca 92.3%. W
zale&#380;no&#347;ci od tego, gdzie napisany system zosta&#322;by u&#380;yty, warto&#347;&#263; t&#261; mo&#380;na
zmodyfikowa&#263;. W przypadku, gdy system zosta&#322;by u&#380;yty w miejscu, gdzie b&#322;&#281;dy
fa&#322;szywie pozytywne s&#261; niedopuszczalne, warto&#347;&#263; ta powinna zosta&#263; zmniejszona.
Spowoduje to, &#380;e ogólna skuteczno&#347;&#263; walidatora spadnie, natomiast cz&#281;stotliwo&#347;&#263;
wyst&#281;powania wyników fa&#322;szywie pozytywnych zostanie <span
class="qx-lmbx-12">najprawdopodobniej</span>
ograniczona.
<!--l. 27--><p class="indent" >   Wymagania, jakie zosta&#322;y podstawione systemowi w rozdziale pierwszym, zosta&#322;y w
pe&#322;ni zrealizowane. Wyniki testów pokaza&#322;y, &#380;e aplikacja poprawnie rozpoznaje zdj&#281;cia
niezawieraj&#261;ce twarzy, jest w stanie równie&#380; oceni&#263; z wysokim prawdopodobie&#324;stwem czy
osoba rozpoznana na zdj&#281;ciu jest znana systemowi oraz zwróci&#263; informacj&#281; na temat
osoby przes&#322;anej do systemu po jej rozpoznaiu




   <h2 class="likechapterHead"><a
 id="x1-350005.5"></a>Spis rysunków</h2>
<a
 id="Q1-1-37"></a>
   <div class="tableofcontents"><span class="lofToc" >&#x00A0;<a
href="#x1-5002">2.1                                                  Schemat blokowy
zaprojektowanego systemu</a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-8002">3.1
Wizualizacja przestrzeni sk&#322;adaj&#261;cej si&#281; z wygenerowanych wektorów.
Odleg&#322;o&#347;ci mierzone metryk&#261; euklidesow&#261; pomi&#281;dzy wektorami
reprezentuj&#261;cymi te same osoby s&#261; mniejsze wzgl&#281;dem wektorów
reprezentuj&#261;cych inne osoby. Liter&#261; &#8220;A&#8221; zosta&#322;y oznaczone zdj&#281;cia
przedstawiaj&#261;ce t&#281; sam&#261; osob&#281;. </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-10003">3.2
Uproszczony schemat obrazuj&#261;cy zasad&#281; dzia&#322;ania funkcji strat
<span
class="qx-lmri-12">triplet loss </span></a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-10015">3.3                                                  Proces uczenia
si&#281; sieci o architekturze FaceNet z podzia&#322;em na poszczególne etapy
</a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-14002">3.4                                                  Model maszyny wektorów no&#347;nych.
Po lewej mo&#380;liwe po&#322;o&#380;enia hiperp&#322;aszczyzny, po prawej zoptymalizowany
model SVM. </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-16003">3.5                                                  Przyk&#322;ad próbek
nieliniowo rozdzielnych </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-16006">3.6                                                  Wp&#322;yw
zmiennej C na szeroko&#347;&#263; marginesu </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-17003">3.7
Zestaw        danych        nie        separowalnych        liniowo
</a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-17005">3.8                                                  Sposób wyznaczania nieliniowej
granicy decyzyjno&#347;ci </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-18002">3.9                                                  Strategia
jeden przeciwko wszystkim </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-18004">3.10
Strategia jeden kontra jeden </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-23002">4.1
Wizualizacja szukanego progu podobie&#324;stwa. Je&#380;eli odleg&#322;o&#347;&#263; pomi&#281;dzy
punktami jest zmniejsza ni&#380; warto&#347;&#263; &#8220;x&#8221; to program powinien uzna&#263;, &#380;e
wektory opisuj&#261; t&#281; sam&#261; osob&#281;. </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-24010">4.2
Porównanie histogramów odleg&#322;o&#347;ci pomi&#281;dzy wektorami twarzy tych
samych oraz ró&#380;nych osób </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-24012">4.3
Schemat obrazuj&#261;cy najbli&#380;sz&#261; odleg&#322;o&#347;&#263; pomi&#281;dzy nowym wektorem
a zbiorem. Na czerwono zosta&#322;y oznaczone odleg&#322;o&#347;ci do dalszych
wektorów. Na zielono zosta&#322;a oznaczona odleg&#322;o&#347;&#263; do najbli&#380;szego
                                                                                 
                                                                                 
wektora i to wzgl&#281;dem niego system powinien ocenia&#263; podobie&#324;stwo.
</a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-24022">4.4                                                  Porównanie histogramów
najmniejszych odleg&#322;o&#347;ci pomi&#281;dzy zdj&#281;ciami twarzy tych samych oraz ró&#380;nych
osób. </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-25002">4.5                                                  Podzia&#322; zdj&#281;&#263; na grupy. Obok
ka&#380;dej z grupy widnieje liczba osób oraz suma wszystkich zdj&#281;&#263; nale&#380;&#261;ca do
owej grupy. </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-25014">4.6                                                  Skuteczno&#347;&#263; walidatora
(funkcji oceniaj&#261;cej, czy podane wektory dotycz&#261; tej samej osoby) w zale&#380;no&#347;ci
od warto&#347;ci progu (parametru &#8220;x&#8221;) </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-27002">4.7
Wygl&#261;d strony internetowej po wybraniu zdj&#281;cia z dysku i uzyskaniu
odpowiedzi z serwera</a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-28002">5.1                                                  U&#380;yte
zdj&#281;cia do przetestowania systemu. Obok ka&#380;dej grupy przedstawiona
jest etykieta zdj&#281;&#263;.</a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-29002">5.2                                                  Podgl&#261;d
wprowadzonych zdj&#281;&#263; do systemu. </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-30002">5.3
Zachowanie systemu po wprowadzeniu zdj&#281;cia niezawieraj&#261;cego twarzy.
</a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-31002">5.4                                                  Zachowanie systemu po wybraniu
zdj&#281;&#263; nieznanych systemowi </a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-32002">5.5
Zwrócone komunikaty przez system dla wybranych zdj&#281;&#263;. Numer
obok komunikatu przedstawia ID osoby na zdj&#281;ciu w systemie.
</a></span><br /><span class="lofToc" >&#x00A0;<a
href="#x1-32004">5.6                                                  Porównanie zdj&#281;cia wgranego
do systemu (po lewej) ze zdj&#281;ciem &#378;le zakwalifikowanym przez
system (po prawej). </a></span><br />
   </div>

</body></html>

                                                                                 
                                                                                 
                                                                                 


